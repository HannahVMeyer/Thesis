\section{Covariance estimation via bootstrapping}
\label{section:bootstrapping-limmbo}
The key innovation of \gls{limmbo} is to perform the variance decomposition on \(b\) bootstrap samples of \(s\) traits instead of on the whole dataset, and use those bootstrap samples to reconstruct the full \tmatsub{C}{g} and \tmatsub{C}{n} matrices (\cref{fig:vd}). In detail, from the total phenotype set with \(P\) traits, \(b\) subset of \(s\) traits are randomly selected.  \(b\) depends on the overall trait size \(P\) and the sampling size \(s\) and is chosen such that each two traits are drawn together at least \(c\) times (default: \(c=3\)). For each subset, the variance decomposition is estimated via the null model of the \gls{mvlmm}), i.e. without the fixed genetic effect \(\mathbf{x}\) (\cref{eq:vd}) and the $s \times s$ covariance matrices \tmatsupsub{C}{s}{g} and\tmatsupsub{C}{s}{n} recorded. 
%
\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter2/Figures/LiMMBoScheme.pdf}
	\caption[\textbf{Variance decomposition.}]{\textbf{Variance decomposition.} On the left-hand side, the phenotype set of \(P\) traits and \(N\) samples is decomposed into its \(P \times P\) trait-to-trait covariances \tmatsub{C}{g} and \tmatsub{C}{n}, based on the provided genetic sample-to-sample kinship estimate matrix \tmat{R}. The noise sample-to-sample matrix \(\mat{I}\) is assumed to be constant (identity matrix). Standardly, this is done by restricted maximum likelihood estimation of the null model of the \gls{mvlmm} (Eq.~\ref{eq:vd}). However, this direct variance decomposition (VD) via \gls{reml} only works for moderate number of phenotype sizes. For higher trait-set sizes, LiMMBo serves as an alternative to the standard\gls{reml} (right-hand side). Here, the phenotypes' variance components are estimated on \(b\) \(s\)-sized subsets of \(P\) which are subsequently combined into the overall \(P \times P\) covariance matrices \tmatsub{C}{g} and \tmatsub{C}{n}.} 
	 	\label{fig:vd}
\end{figure}
%
For each trait pair, their covariance estimate is averaged over the number of times they were drawn. The challenge lies in combining the bootstrap results in such a way that the resulting \tmatsub{C}{g} and \tmatsub{C}{n} matrices are true covariance matrices i.e. positive semi-definite and serve as good estimators of the true covariance matrices. This is achieved by fitting (least-squares estimate) the covariance estimates of the \(b\) subsets to the closest positive-semidefinite matrices via the BFGS algorithm (\cref{subsection:lmm}, \citep{Byrd1995}), using the average estimates to initiate the matrices. 


\section{Data simulation}
\label{section:data-limmbo}
Using \textit{PhenotypeSimulator} (\cref{chapter:simulation}), I simulated a number of different phenotype datasets to evaluate \gls{limmbo} in terms of scalability, model calibration and power. The datasets differed in their overall trait size \(P\), the percentage of variance explained by genetics \(h_2\) (sum of fixed and random genetic effects) and the number of different phenotype components simulated to create the final phenotype. The phenotypes were simulated as described in \cref{section:phenotype-simulation}, based on the parameters and parameter values described in \cref{tab:pardescription} and \cref{tab:parvalues}. Parameter values were generally chosen to cover a wide range a possible combinations and trait sizes. Parameters for levels of variance explained by the genetic and noise components were set to test their effect on the variance decomposition algorithm of the underlying \gls{lmm} framework \citep{Casale2015}. The variance decomposition is initiated by allocating an even split of variance explained to the genetic and random noise effects. The levels of variance explained were thus set to \(0.5\) each and deviations from this equal split into either direction (\(0.2\), \(0.8\)). 
%

\section{Scalability of LiMMBo}
\label{section:scalability-limmbo}
The complexity of the variance decomposition of the \gls{lmm} framework that \gls{limmbo} builds on is \(O(N^2 + tNP^5)\). The second term depends on the overall trait size and describes the complexity of estimating the trait-by-trait covariance matrices  \tmatsub{C}{g} and  \tmatsub{C}{n}. By bootstrapping \(s\)-sized samples from the overall trait size, this complexity term changes to \(btNs^5\), with the covariance estimation carried out for \(b\) bootstraps. In addition to the estimation of the covariance terms, the overall complexity of \gls{limmbo} also depends on the fitting the BFGS algorithm \(n\) times to the full traitset of size \(P\). \gls{limmbo} makes use of a Cholesky decomposition of the matrices to be fitted, resulting in $\frac{1}{2}P(P+1)$ model parameters to be fitted for both  \tmatsub{C}{g} and  \tmatsub{C}{n}. Thus, the overall complexity of \gls{limmbo} is \(O(N^2 + btNs^5 + nP^2)\), which is the sum of the complexity of the bootstrap variance decompositions and the complexity of fitting the BFGS algorithm.  

In order to assess and compare how \gls{limmbo} scales, I performed variance decomposition both with \gls{limmbo} and the standard \gls{reml} approach on phenotypes with trait sizes ranging from \numrange{10}{100} traits (parameters for phenotype simulation as described in \cref{tab:parvalues}, total of ten simulated datasets per setup). For \(P=10\), the sampling datasize \(s\) was set to \(s=5\), otherwise  \(s=10\).  \Cref{fig:proctime} shows the overall time taken by the standard \gls{reml} approach, \gls{limmbo} and its two main components, the bootstrapping and the combination of the bootstrap results.
% Table generated by Excel2LaTeX from sheet 'SimulateDataParameters'
\begin{table}[htbp]
  \centering
  \caption[\textbf{Parameters for phenotype simulation.}]{\textbf{Parameters for phenotype simulation.} The genetic and noise effects have both a random and fixed effect. For each, the total variance is the sum of their random and fixed effect variance and has to add to 1. Each fixed and random component has a certain percentage of its variance that is shared across traits, while the rest is independent.}
    \begin{tabular}{clrrr}
    \toprule
          &       & variance explained & shared & independent \\
    \midrule
    \multirow{3}[1]{*}{genetic effects} & total & \(h_2\) &       &  \\
          & fixed & \(h_2^s\) & \(\theta\) & 1-\(\theta\) \\
          & random & \(h_2^g\) & \(\eta\) & 1-\(\eta\) \\
   \addlinespace[1.5ex]
    \multirow{3}[1]{*}{noise effects} & total & (1-\(h_2\)) &       &  \\
          & fixed & (1-\(h_2\))\(\delta\) & \(\gamma\) & 1-\(\gamma\) \\
          & random & (1-\(h_2\))(1-\(\delta\)) & \(\alpha\) & 1-\(\alpha\) \\
    \bottomrule
    \end{tabular}%
  \label{tab:pardescription}%
\end{table}%
%
% Table generated by Excel2LaTeX from sheet 'SimulateDataValues'
\begin{table}[htbp]
  \centering
  \caption[\textbf{Parameter values of simulated phenotypes for assessing scalability, calibration and power.}]{\textbf{Parameter values of simulated phenotypes for assessing scalability, calibration and power.} The `genotype' parameter specifies the simulated genotype cohort which was used to simulate fixed and random genetic effects (described in \cref{section:genotype-simulation}). \(P\) are the different traitset sizes that were simulated. The parameters that follow are described in \cref{tab:pardescription} and specify the variance explained by each of the phenotype components. A variance explained equals zero means that this component was not simulated and corresponding non-applicable variance terms are designated with \textquote{-}.} 
    \begin{tabular}{lrr}
    \toprule
          & \multicolumn{2}{c}{Parameter values} \\
\cmidrule{2-3}    Parameter & Power  & Calibration \\
    \midrule
    \multicolumn{1}{c}{\multirow{3}[1]{*}{Genotypes}} & \multicolumn{1}{c}{\multirow{3}[1]{*}{relatedNoPopstructure}} & relatedNoPopstructure \\
          &       & unrelatedNoPopstructure \\
          &       & unrelatedPopstructure \\
          \addlinespace[1.5ex]
    \(P\) & 10, 50, 100 & 10, 20, \(\ldots\), 100 \\
   \addlinespace[1.5ex]
    \(h_2^s\) & 0.48, 0.3, 0.12 & 0 \\
    \(h_2^g\) & 0.32, 0.2, 0.08 & 0.8, 0.5, 0.2 \\
    \(h_2\) & 0.8, 0.5, 0.2 & 0.8, 0.5, 0.2 \\
    (1-\(h_2\))\(\delta\) & 0.08, 0.2, 0.32 & 0 \\
    (1-\(h_2\))(1-\(\delta\)) & 0.12, 0.3, 0.48 & 0.2, 0.5, 0.8 \\
    (1-\(h_2\)) & 0.2, 0.5, 0.8 & 0.2, 0.5, 0.8 \\
    \(\theta\) & 0.6   &  - \\
    \(\eta\) & 0.8   & 0.8 \\
    \(\gamma\) & 0.6   &  - \\
    \(\alpha\) & 0.8   & 0.8 \\
    \bottomrule
    \end{tabular}%
\label{tab:parvalues}%
\end{table}%
%
\begin{figure}[H]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.8\textwidth]{Chapter2/Figures/proctime.pdf}
	\caption[\textbf{Scalability of LiMMBo compared to standard REML.}]{\textbf{Scalability of LiMMBo compared to standard REML}. Empirical run times for \gls{limmbo} and the standard \gls{reml} approach on three simulated datasets per phenotype size, with \(N=\)\num{1000} individuals each and different amount of variance explained by the genetic background signal (\num{0.2}, \num{0.5}, \num{0.8}). Points mark the mean run time across the different set-ups, error bars indicate their standard deviation. Lines were fitted for the bootstrapping step (orange): \(n(s^2 + s^5)\); the combination of the bootstrapping (blue): \(\frac{1}{2}P(P+1)\) and their combined run time (turquoise):  \(n(s^2 + s^5) + \frac{1}{2}P(P+1)\). \(b\): number of bootstraps, \(s\): bootstrap size, \(P\): phenotype size. The majority of the run time is required for the bootstrapping. The run time for the standard \gls{reml} results (red) are only depicted up to \(P=40\) when they already exceed the run times for \(P=100\) in the \gls{limmbo} approach (\gls{reml}: \(O(N^2 + t(NP^2 + NP^5))\)).}
	 	\label{fig:proctime}
\end{figure}
%
The majority of the run time of \gls{limmbo} is taken by the variance decomposition of the bootstrapped subsets, which accounts for at least \num{85}\%  (\num{70} traits) and on average \num{97}\%  of the total run time. As a comparison, the time taken by the standard \gls{reml} approach quickly exceeds the time of \gls{limmbo} and becomes unfeasible for more than \num{30} traits. 
 
While the bootstrapping keeps the complexity of \gls{limmbo} effectively at \(O(P^2)\), it has the major advantage of allowing for parallelisation of the covariance estimation step. Thus, \gls{limmbo} computes the variance decomposition of each bootstrap independently and enables the use of multiple cores, allowing for an additional speed up of the process. 


\section{LiMMBo yields covariance estimates consistent with REML estimates for moderate trait numbers}
\label{section:covariance-limmbo}
I evaluated the suitability of \gls{limmbo} for covariance estimation of \tmatsub{C}{g} and \tmatsub{C}{n} on simulated datasets with different strength of background genetic effects. I simulated phenotype sets composed of background genetic effects \tmat{G} and noise effects \tmat{\Psi} only, omitting any specific genetic effects (additional parameters as described in \cref{tab:parvalues}) and estimated these variance components subsequently with \gls{limmbo} and standard \gls{reml}. Variance estimation on simulated datasets allows for the comparison of the estimated covariance matrices to the true covariance matrices based on which the phenotypes were simulated. By computing the \gls{rmsd} between the true and estimated covariance matrices from both methods, I obtain a measure that is directly comparable and independent of the trait set: 
\begin{equation}
\text{RMSD}=\sqrt{\frac{\sum_{t=1}^n (C_{\text{true}} - C_{\text{estimate}})^2}{n}}
\label{eq:rmsd}
\end{equation}
\Cref{fig:covsimilarity} shows the comparison of both standard \gls{reml} and \gls{limmbo}-derived covariance matrices compared to the simulated, true covariance matrices. In the regime where \gls{reml} is feasible, i.e. moderate trait sizes of up to \num{30}, the RMSD can directly be compared: both methods provide consistent estimates across trait sizes with little difference between the methods. Importantly, the \gls{rmsd} stays constant for the \gls{limmbo}-derived estimates of the covariances, even for phenotypes of higher sizes. 

\begin{figure}[h]
	\centering	
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.6\textwidth]{Chapter2/Figures/covarianceSummary.pdf}\\
	\caption[\textbf{Comparison of trait-by-trait covariance estimates derived from standard REML and LiMMBo.}]{\textbf{Comparison of trait-by-trait covariance estimates derived from standard REML and LiMMBo.} Phenotypes with different percentage of variance explained by genetics (\(h_2={0.2, 0.5, 0.8}\)) and different trait numbers were simulated. Subsequently, the genetic and noise trait-by-trait covariance matrices \tmatsub{C}{g} and \tmatsub{C}{n} were estimated both via \gls{limmbo} and standard \gls{reml}. These estimates were compared to the true (simulated) covariance matrix by computing their root mean squared deviation (\gls{rmsd}; \cref{eq:rmsd}). The boxplots summarise the \gls{rmsd} across different variance levels. For moderate traitset sizes ranging from \numrange{10}{30} traits, \gls{limmbo} and the \gls{reml} approach yield consistent covariance estimates. Covariance estimation via \gls{limmbo} stays stable with these observations in the higher trait sizes (\(P={50,100}\)). }
	  \label{fig:covsimilarity}%
\end{figure}

\section{mtGWAS with LiMMBo-derived covariance matrices are well calibrated across all phenotype sizes}
\label{section:calibration-limmbo}
One key aspect in statistical method development is to ensure that the method is well-calibrated under the null model. Apart from gaining knowledge about the genetic and noise trait-by-trait covariance structure of a phenotype, variance decomposition into different random effect components yields estimates that can be supplied as known parameters to approximate \gls{mvlmm} methods and \gls{mtgwas}. As introduced by \citet{Jiang1995} and adapted by \citet{Korte2012}, there are different model designs for \gls{mvlmm}, depending on the underlying biological hypothesis regarding the effect of the genetic variant. The different models were described in \cref{subsubsection:model-design} and include any effect (effect size is unequal to zero for at least one trait), common effect (same effect size across all traits) and specific effect test (specific effects of the variant on a given trait). In practice, it is common to test for any effect as a means of discovering associated genotypes and to refine the type of association later. As such, I chose to apply an any effect test for both the calibration and power analysis.

In order to test if \gls{limmbo}-derived covariance estimates yield well calibrated test statistics, I simulated phenotype sets composed of random genetic and noise effects only with \num{10}, \num{20}, \num{30}, \num{50} and \num{100} traits and parameters described in \cref{tab:parvalues}. For trait sizes of up to \num{30} traits, I compared the calibration of \gls{mtgwas} for \gls{limmbo}- and \gls{reml}-derived covariance matrices. As shown in \cref{fig:calibration}, both methods yield p-values following a uniform distribution under the null model across all phenotype sizes and variance explained by genetics, thus show appropriate calibration. 
%
\begin{figure}[h!]
	\centering	
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip,width=0.98\textwidth]{Chapter2/Figures/calibrationSummaryQQAll}\\
	\caption[\textbf{Calibration of mtGWAS based on covariance estimates from standard REML and LiMMBo.}]{\textbf{Calibration of mtGWAS based on covariance estimates from standard REML and LiMMBo.} For moderate traitset sizes ranging from \numrange{10}{30} traits, phenotypes with different percentage of variance explained by genetics were simulated. For each setup, ten random datasets were generated. The genetic and noise trait-by-trait covariance matrices \tmatsub{C}{g} and \tmatsub{C}{n} were then estimated both via \gls{limmbo} and standard \gls{reml}. The model calibration i.e. uniform distribution of p-values under the null model was assessed by \gls{mtgwas} with covariance estimates derived from either \gls{limmbo} or \gls{reml}. Quantile-quantile plots show uniform distribution for both methods across all trait sizes and levels of proportion of variance explained by genetics.}
	  \label{fig:calibration}%
	  \vspace{-2mm}
\end{figure}
%

For higher trait sizes, I also compared the calibration of \gls{mtgwas} using a \gls{mvlmm} to using a simple \gls{mvlm}. The \gls{mvlm} does not require the variance decomposition into different random effects, i.e. avoids the computational bottleneck, but simply uses principal components of the genotypes as fixed effects to adjust for population structure. For the residual trait-by-trait covariance structure \(\sigma_n\), I used the empirical phenotypic trait-by-trait covariance. As depicted in \cref{fig:calibration-LM}, the calibration of the \gls{mvlm} depends strongly on the population structure. For populations without related individuals, the \gls{mvlm} shows a uniform p-value distribution and points to the usefulness of this simpler model approach for populations with well-defined structure. However for structured populations, the \gls{mvlm} is poorly calibrated and clearly demonstrates the difficulty of adjusting for population structure via fixed effects in highly structured populations. In these scenarios, multi-trait mapping of high-dimensional phenotypes is only possible via \gls{limmbo}. 
%
\begin{figure}[h!]
	\centering	
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter2/Figures/calibrationSummaryQQLMMvsLM}\\
	\caption[\textbf{Calibration of mtGWAS via a simple linear model and a linear mixed model. }]{\textbf{Calibration of mtGWAS via a simple linear model and LiMMBo.} The three phenotype sets with \num{100} traits each were modelled as the sum of random noise and genetic effects. The basis for the random genetic effects build the three genotype cohorts simulated in \cref{section:genotype-simulation}. The phenotypic variance explained by genetics was set to \(h_2=0.8\). For the \gls{mvlmm} (only shown for the population with related individuals), covariance estimates were derived via \gls{limmbo}. In the \gls{mvlm}, population structure was adjusted for via the first ten \glspl{pc} of the genotype data. The \gls{mvlm} is well calibrated for populations without related individuals. For the populations containing the latter, only the \gls{mvlmm} is well calibrated. }
	  \label{fig:calibration-LM}%
\end{figure}

\section{Multi-trait genotype to phenotype mapping increases power for high-dimensional phenotypes}
\label{section:power-limmbo}

Multi-trait linear mixed models for low to moderate phenotype sizes have been shown to improve power by leveraging correlated background structure and trait-by-trait correlations resulting thereof \citep{Casale2015}. For assessing the significance of the genotype-phenotype association via \gls{llr} test statistics where the likelihood of the full model is compared to the likelihood of the null model i.e. without the fixed genetic effect, the \gls{llr} statistic are translated into p-values via the appropriate \(\chi^2\) distribution with \(P\) degrees of freedom (\cref{subsection:hypothesis-testing,fig:GWAS-stats},\citep{Wilks1938}).  In order to test if there is still a gain in power for a \gls{mvlmm} with high-dimensional phenotypes, i.e. large number of degrees of freedom, I simulated phenotypes where I varied key parameters whose influence on power I wanted to investigate. 

I varied trait size (\(P=\left\{10,50,100\right\}\)), genetic background contribution to the phenotypic variance (\(h_2=\left\{0.2,0.5,0.8\right\}\) and proportion of traits that are affected by the fixed genetic effects (\(a=\left\{0.2, 1\right\}\)). I simulated the phenotypes composed of random genetic and fixed and random noise effects with parameters described in \cref{tab:pardescription} and \cref{tab:parvalues}. For each of these phenotype sets, I added \num{20} fixed genetic effects to a subset of traits, creating phenotypes with different proportions of traits affected by the fixed effect genetics.  For each set-up, I simulated \num{50} independent phenotypes (a total of \( 2,250 \text{ phenotypes} = 3\text{ }h_2 \times 3 \text{ trait sizes} \times 50 \text{ permutations} \times 5 \text{ subset sizes}\)) and estimated the trait-by-trait covariance matrices \tmatsub{C}{g} and \tmatsub{C}{n} via \gls{limmbo}. I used these estimates in a \gls{mvlmm} to test the association between the known causal \glspl{snp} (from the simulation) and the phenotypes. In addition, I determined the association of the causal \glspl{snp} for each trait independently via \gls{uvlmm}. The significance of the associations was assessed by comparing the p-values of these original associations to p-values obtained from \gls{mvlmm} and uvLMM on \num{1000} permutation of the genotypes.  For the \gls{uvlmm}, the p-values were adjusted for multiple testing by the number of traits that were tested and the minimum adjusted p-value across all traits for a given \gls{snp} recorded. For each \gls{snp}, the number of times the (adjusted) p-value of the permutation was less or equal to the observed p-value was recorded and divided by the total number of permutations, yielding an empirical p-value per \gls{snp}.

I compared the results of the univariate and multivariate models to evaluate  two key differences in the models. First, I can test which burden of the multiple association testing weights heavier, the correction for multiple testing in the \gls{uvlmm} or the increased degrees of freedom in the \gls{mvlmm}. This effect can be analysed by varying the number of traits in the phenotypes and keeping the other parameters constant. As depicted in \cref{fig:power}\subfig{A}, for the highest number of phenotypes tested, both models are comparable in the number of causal \glspl{snp} they detect. For the other trait sizes tested, the multivariate model out-performs the univariate model by far. For these comparisons, an ideal scenario was assumed and all traits were affected by the fixed genetics affects (\(a=1\)) and the total genetic variance was low (\(h_2=0.2\)). 
%
\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.9\textwidth]{Chapter2/Figures/power.pdf}
	\caption[\textbf{Power comparison for mvLMM and uvLMMs of high-dimensional phenotypes.}]{\textbf{Power comparison for mvLMM and uvLMMs of high-dimensional phenotypes.} Each panels show the influence of one simulation parameter on the power to detect the causal \glspl{snp}. When investigating one parameter, the other parameters were fixed at a certain value. For each set-up, 50 independent datasets were simulated and analysed. A. Influence of the number of traits: proportion of traits affected and the total genetic variance fixed at \(a=1\) and \(h_2=0.2\), respectively. B. Influence of proportion of traits affected: trait size and total genetic variance fixed to \(P=50\) and \(h_2=0.2\) respectively. C. Influence of total genetic variance:  trait size and  proportion of traits affected fixed to \(P=100\) and \(a=0.6\).} 
 	\label{fig:power}
\end{figure}

The influence of the proportion of traits affected by the causal \glspl{snp} on the power to detect these is depicted in \cref{fig:power}\subfig{B}. This analysis allows for the evaluation of the second key difference in the models. The multivariate model can exploit correlated background structure and allows for the detection of pleiotropic effects, while the univariate model can only detect simple \gls{snp}-trait associations. This advantage becomes clear in \cref{fig:power}\subfig{B}, where the median number of detected true \glspl{snp} depending on the proportions of traits affected by the causal \glspl{snp} is depicted. Here, the number of traits was kept constant at \(P=50\) and the mean genetic variance across all traits fixed at \(h_2=0.2\), i.e. with an increase of the number of affected traits the contribution of the genetic component per trait decreases. The univariate model suffers from the weaker genetic components when a large number of traits are affected and loses power. In contrast, the multivariate model can still detect increasing percentages of true causal \glspl{snp}. The influence of the proportion of phenotypic variance explained by all genetic, i.e. fixed and random genetic effects is shown in \cref{fig:power}\subfig{C}. For both models, the number of detected \glspl{snp} decreases with increasing \(h_2\), as the effect sizes of the \glspl{snp} become negligible compared to the overall genetic variance. However, the multivariate model is still able to exploit the correlation of the fixed effects across traits and detects more \glspl{snp} in cases of high \(h_2\). An overview of all parameter comparisons can be found in \cref{fig:power-all} in the appendix. 
 