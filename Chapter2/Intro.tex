\chapter{Extending linear mixed models to high-dimensional phenotypes}
\label{chapter:limmbo}
Different strategies and challenges for multi-trait \gls{gwas} of high-dimensional phenotypes have been discussed in \cref{subsection:joint-analysis}. Phenotypes can either be transformed into a lower dimensional space prior to the association study or the summary statistics from single-trait \gls{gwas} can be combined post-hoc to obtain quasi multi-trait association results. In contrast, multivariate \glspl{lmm} can directly model the genotypic association across a moderate number of phenotypes. In the following chapter, I will describe the challenges of multivariate \glspl{lmm} for high-dimensional phenotypes and present LiMMBo, a new method for the genotype-phenotype mapping of high-dimensional datasets. 

\glspl{lmm} have become a workhorse in genetic association studies as they allow to control for complex sample-by-sample covariance structures that can reflect population structure and relatedness (discussed in detail in \cref{subsection:lmm-genetics}). In summary, \glspl{lmm} commonly describe the phenotype as a linear combination of fixed effects -- experimental and/or technical  covariates and the genotype marker of interest, and a random genetic effect and residual noise which capture the genetic and residual covariances between traits. The association of the genetic marker is evaluated by comparing the alternative hypothesis that the genotype has an effect on the phenotype which is unequal to zero to the null model of no effect (\cref{subsubsection:model-design}). In practice, this means estimating the effect size of the fixed genetic effects and the random effect covariance terms for the alternative model and the random effect covariance terms for the null model where the effect size of the genetic marker is zero. 

The first \gls{lmm} implementations estimated all variance components (genotype ef- fect size and random effect covariance terms, \cref{eq:lmm-mv-likelihood}) anew for each \gls{snp}-phe\-notype association. However, in human genetics effect sizes are generally assumed to be small compared to the overall phenotypic variance \citep{Kang2010,Zhang2010}. Consequently, estimates of the random effect covariance terms under the null model can serve as a good approximation. Based on these differences in the estimation of the random effect covariance terms, \glspl{lmm} can broadly be grouped into two categories. The exact methods with covariance estimates under the alternative model and approximate methods, where the random effect covariance terms are only estimated once under the null model of no fixed genetic effect and are then used as predefined random effects in the alternative models for all genome-wide associations. 

Within these two categories, one can further distinguish between methods only applicable as univariate tests or methods that allow for multivariate testing. \Cref{tab:lmmframeworks} summarises commonly used frameworks and describes their computational complexity\footnote{The computational complexity and algorithms for the GCTA implementations \citep{Yang2011} of multivariate genetic variance estimation \citep{Lee2012} and \gls{lmm} for association testing \citep{Yang2014} could not be found in the original publications and are therefore not listed}.
\\
% Table generated by Excel2LaTeX from sheet 'LMMOverview'
\begin{table}[h]
  \centering
  \caption[\textbf{Linear mixed model frameworks for genetic association studies.}]{\textbf{Linear mixed model frameworks for genetic association studies.} A list of popular \gls{lmm} frameworks, grouped by their usage of covariance estimates when fitting the alternative model (first column: E:exact, A: approximate). The complexity describes the complexity for fitting a single \gls{lmm} as specified in the original publication or summarised elsewhere, as indicated by the footnotes. \(P\) indicates the trait size that the model was designed for (according to the original publication). Models with specific parameters are described in more detail in the text (FaST-LMM-select and TASSEL). \(N\): number of samples;  \(s_c\): number of SNPs used for singular value decomposition; \(c\):  compression factor with \(c=\frac{N}{g}\) for \(g\) individuals per group; \(t, t_1 \text{and} t_2\): average number of iterations needed to find parameter estimates. GRAMMAR-Gamma, FaST-LMM-select: \(t\) steps of the Brent's algorithm;  GEMMA, MTMM: \(t_1\) steps of the EM algorithm, \(t_2\) steps of the NR algorithm; BOLT-LMM: \(t\) steps of the variational Bayes and conjugate gradients; TASSEL: \(t\) steps of the ProcMixed algorithm in SAS; mtSet: \(t\) steps of the L-FBGS.}
  \begin{small}
     \begin{tabular}{llrrr}
    \toprule
     & Framework & Complexity \(O\) & \(P\) & Reference \\
    \midrule
    \multirow{3}[1]{*}{E} & FastLMM-select & \(Ns_c^2 + N^2 + tN\) & \num{1} & \citep{Lippert2011} \\
          & \multicolumn{1}{l}{\multirow{2}[0]{*}{GEMMA}} & \(N^3 + N^2P  + \)&  \multirow{2}[0]{*}{\num{10}} & \citep{Zhou2014} \\
          \addlinespace[-.2ex]
          & & \( t_1NP^2 + t_2NP^6\) & &\citep{Zhou2014} \\
    \addlinespace[3ex]
    \multirow{9}[1]{*}{A} & \multicolumn{1}{l}{\multirow{2}[0]{*}{MTMM}}  & \(t_1N^3P^3 + t_2N^3P^7 \) &  \multirow{2}[0]{*}{\num{2}} &  \multirow{2}[0]{*}{\citep{Korte2012}}\footnotemark[2] \\
                    \addlinespace[-.2ex]
          &  & \(+ N^2P^2\) & & \\
    		& EMMAX & \(N^3 + tN + N^2\) & \num{1} & \citep{Kang2010} \\
          & TASSEL & \(\frac{1}{c^3}N^3\) & \num{1} & \citep{Zhang2010} \\
          & GRAMMAR- & \multirow{2}[0]{*}{\(N^3 + tN + N\)} & \multirow{2}[0]{*}{\num{1}} & \multicolumn{1}{r}{\multirow{2}[0]{*}{\citep{Svishcheva2012}}} \\
          \addlinespace[-.5ex]
          & Gamma &       &       &  \\
          & BOLT-LMM & \(tN\) & \num{1} & \citep{Loh2014} \\
          & mtSet & \(N^3 + N^2 + tNP^5\) & \num{10} & \citep{Casale2015} \\
    \bottomrule
    \end{tabular}
  \end{small}
  \label{tab:lmmframeworks}%
\end{table}%
%
Among the exact methods, FaST-LMM-select reduces the complexity best in terms of sample size by selecting the number of \glspl{snp} to use for the estimation of the \gls{rrm}.  However, it can only be applied in univariate analyses while MTMM and GEMMA extend to multivariate cases.  BOLT-LMM scales best with increasing samples sizes in the group of approximate tests, by directly using the genotypes and not computing or storing the \gls{rrm}. All other methods have an upfront \(O(N^3)\) operation for the eigendecomposition of the \gls{rrm}. TASSEL reduces this complexity based on grouping of the samples and thereby effectively reducing the size of the \gls{rrm}.
%\citet{Eu-ahsunthornwattana2014} analysed several LMM frameworks including FaST-LMM, GEMMA and EMMAX with respect to their control for type I errors and estimation of kinships and compared the results obtained from each method. They find that the results of most methods tested are in concordance and their performance similar in terms of power and calibration when applied to real and simulated data. In conclusion, they recommend to choose a framework based on complexity and data structure requirements. 

With the generation of ever-increasing cohort sizes in genetic association studies, most \gls{lmm}frameworks are optimised for the number of samples as described above for BOLT-LMM and TASSEL. While the remaining methods still have the upfront cubic computation of the  \gls{rrm}'s eigendecomposition, subsequent steps have been adapted to scale linearly or quadratically with the number of samples for the majority of the applications. The reduced complexity in the sample term comes as a trade-off with the number of traits that can be analysed. From the multivariate methods listed above, the complexity in terms of trait number ranges from \(O(P^5)\) to \(O(P^7)\) which originates from the estimation of the trait-by-trait covariance components of the random effects and, in practice, limits these models to moderate trait numbers\footnotetext[2]{Listed in \citep{Zhou2014}}.

\section{LiMMBo: Linear mixed modeling with bootstapping}
\label{section:intro-limmbo}
To extend the range of \glspl{lmm} for high-dimensional phenotype sets, I chose to build on an approximate model in order to avoid the repeated estimation of the trait-by-trait covariance matrices. In that respect, the multivariate \gls{lmm} developed by Lippert, Casale and colleagues \citep{Lippert2014,Casale2015} harboured many advantages. It is computationally efficient for a moderate number of traits, has successfully  been used in multi-trait studies \citep{Cannavo2016,Schor2017} and collaboration with its developers was easily realisable. 
Their model is cast as
\begin{equation}
\mat{Y} = \mat{G} + \mat{\Psi},
\label{eq:vd}
\end{equation}
%
where the \(N \times P\) phenotype matrix \tmat{Y} for \(N\) individuals and \(P\) traits is modelled as the sum of a genetic (or polygenic) component \tmat{G} and a noise component \tmat{\Psi}. Here, \tmat{G} and \tmat{Psi} are random effects following multivariate normal matrix distributions:
\begin{equation}
\begin{aligned}
\mat{G} &\sim\matrixnormal N P {\mat{0}}{\mat{R}} {\matsub{C}{g}}  \\
\mat{\Psi} &\sim\matrixnormal N P {\mat{0}}{\mat{I}_N} {\matsub{C}{n}}.
\end{aligned}
\end{equation}
%
where \tmat{R} is the genetic relationship matrix, \tmatsub{I}{N} is the \(N \times N\) identity matrix while \tmatsub{C}{g} and \tmatsub{C}{n} are the genetic and residual trait covariance matrices, respectively. This model has been used to decompose the phenotypic covariances into genetic and environmental covariances via restricted marginal likelihood (\gls{reml}). 

The complexity of the variance decomposition model (\cref{eq:vd}) is \(O(N^2 + NP^5)\) with \(N\) the number of samples, \(P\) the number of traits, and \(t\) the number of iterations of Broyden's method (\cref{subsection:lmm}) for optimising the \gls{reml} of the parameter estimates. From this equation, it becomes evident that as the number of traits increases, the complexity increases by a power of four and explains why this \gls{lmm} set-up is not feasible for large trait sets. To overcome the bottleneck of estimating the trait-by-trait covariance matrices as a whole which is the reason for the complexity of \(P^5\), I developed a simple method that efficiently uses a \gls{limmbo} approach to estimate \tmatsub{C}{g} and \tmatsub{C}{n}.