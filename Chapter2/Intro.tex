\chapter{Extending linear mixed models to high-dimensional phenotypes}
\label{chapter:limmbo}
Linear mixed models have become a workhorse in genetic assocation studies as they allow to control for complex sample-to-sample covariance structures that can reflect population structure and relatedness. LMM can broadly be grouped into two categories, based on the estimation of their random effect covariance terms. Exact methods estimate the covariance term anew for each SNP, while approximate methods rely on the assumption that the effect sizes of the fixed effects are sufficiently small \citep{Kang2010,Zhang2010} and an estimate of the covariance terms under the null is a good approximation. Hence, in these methods, the covariance terms are only estimated once under the null model of no fixed genetic effect and are then used as estimates in the genome-wide associations. Within these categories, one can further distinguish between methods only applicable as univariate test or tests that allow for multivariate testing. \Cref{tab:lmmframeworks} summarizes commonly used frameworks and describes their computational complexity.  Amongst the exact methods, FaST-LMM reduces the complexity best in terms of sample size by selecting the number of SNPs to use for the estimation of the GRM.  However, it can only be applied in univariate analyses while MTMM and GEMMA extend to multivariate cases.  BOLT-LMM scales best with increasing samples sizes in the group of approximate test, by directly using the genotypes and not computing or storing the GRM. All other methods have an upfront \(O(N^3)\) operation for the eigendecomposition of the GRM. TASSEL reduces this complexity based on grouping of the samples and thereby effectively reducing the size of the GRM.

% Table generated by Excel2LaTeX from sheet 'LMMOverview'
\begin{table}[htbp]
  \centering
  \caption[\textbf{Linear mixed model frameworks for genetic association studies.}]{\textbf{Linear mixed model frameworks for genetic association studies.} A list of popular LMM frameworks, grouped by their usage of covariance estimates when fitting the alternative model (method). \(P\) indicates the maximum trait sizes that the model can be applied to. Models with specific parameters are described in more detail in the text (FaST-LMM and TASSEL). \(N\): number of samples; \(P\): number of traits; \(S_c\): number of SNPs used for singular value decomposition; \(c\):  compression factor with \(c=\frac{N}{g}\) for \(g\) individuals per group; \(t, t_1 \text{and} t_2\): average number of iterations needed to find parameter estimates. GRAMMAR-Gamma, FaST-LMM:\(t\) for Brenth's algorithm;  GEMMA, GCTA, MTMM: \(t_1\) for EM algorithm, 
 \(t_2\) for NR algorithm; BOLT-LMM: \(t\) for variational Bayes and conjugate gradients; TASSEL: \(t\) for ProcMixed algorithm in SAS; mtSet: \(t\) for LFBGS.}
\begin{tabular}{llrrr}
    \toprule
    Method & Framework & Complexity for single LMM & \(P\) & Reference \\
    \midrule
    \multirow{3}[1]{*}{exact} & FastLMM & \(O(Ns_c^2 + N^2 + tN)\) & \num{1} & \citep{Lippert2011} \\
          & MTMM  & \(O(t_1N^3P^3 + t_2N^3P^7 + N^2P^2)\) & \num{2} & \citep{Korte2012} \\
          & GEMMA & \(O(N^3 + N^2P  +  t_1NP^2 + t_2NP^6)\) & \num{10} & \citep{Zhou2014} \\
    \addlinespace[1.5ex]
    \multirow{6}[1]{*}{approximate} & EMMAX & \(O(N^3 + tN + N^2)\) & \num{1} & \citep{Kang2010} \\
          & TASSEL & \(O(\frac{1}{c^3}N^3)\) & \num{1} & \citep{Zhang2010} \\
          & GCTA  & \(O(t_1N^3P ^3 + t_2N^3P^7)\) & \num{2} & \citep{Yang2011} \\
          & GRAMMAR-Gamma & \(O(N^3 + tN + N)\) & \num{1} & \citep{Svishcheva2012} \\
          & BOLT-LMM & \(O(tN)\) & \num{1} & \citep{Loh2015} \\
          & mtSet & \(O(N^3 + N^2 + t(NP^2 + NP^4)\) & \numrange{10}{30} & \citep{Casale2015} \\
    \bottomrule
    \end{tabular}%
  \label{tab:lmmframeworks}%
\end{table}%

Eu-Ahsunthornwattana and colleagues \citeyear{Eu-ahsunthornwattana2014} analysed several LMM frameworks including FaST-LMM, GEMMA and EMMAX with respect to their control for type I error and estimation of kinships and compared the results obtained from each method. They find that the results of most methods tested are in concordance and their performance similar in terms of power and calibration when applied to real and simulated data. In conclusion, they recommend to choose a framework based on complexity and data structure requirements. 

With the generation of ever-increasing cohort sizes in genetic assocation studies, most LMM frameworks are optimised for the number of samples as described above for BOLT-LMM and TASSEL. While the remaining methods still have the upfront cubic computation of the GRM's eigendecomposition, subsequent steps have been adapted to scale linearly or quadratically with the number of samples for the majority of the applications. The optimisation in scaling for the sample dimenison comes as a trade-off for the scaling in the number of traits that can be analysed. From the multivariate methods listed above, the complexity in terms of trait number ranges from \(O(P^4)\) to \(O(P^7)\) which originates from the estimation of the trait-by-trait covariance component of the random effect and, in practice, limits these models to moderate trait numbers.

\section{LiMMBo: Linear mixed modeling with bootstapping}
\label{section:intro-limmbo}
To extend the range of LMMs for high-dimensional phenotype sets, I chose to build on an approximate model in order to avoid the repeated estimation of the trait covariance matrices. The multivariate LMM developed by Lippert, Casale and colleagues (mtSet) \citeyear{Lippert2014,Casale2015} is the only approximate model that is computationally efficient for 10-30 traits, depending on the sample and trait covariance structures. Within this framework, the genetic variance \(\mat{G} \sim \multinormal N P 0 {\matsub{C}{g} \otimes \matsub{R}{N}}\) and the noise variance component \(\mat{\Psi} \sim \multinormal N P 0 {\matsub{C}{n} \otimes \matsub{I}{N}}\) are estimated by fitting the null model of the mvLMM (Eq.~\ref{eq:mvLMM}; omitting covariates for simplicity):

\begin{equation}
\text{vec}(\mat{Y}) \sim \multinormal N P 0 {\matsub{C}{g} \otimes \mat{R} + \matsub{C}{n} \otimes \matsub{I}{N}}
\label{eq:vd}
\end{equation}

The covariance structure of \tmat{G} and \tmat{\Psi} is described by the Kronecker product $\otimes$ of the genetic trait-to-trait covariance matrix\tmatsub{C}{g} with the genetic sample-to-sample relationship matrix \tmat{R} and of the noise trait-to-trait covariance matrix  \tmatsub{C}{n} with the identity matrix \tmatsub{I}{N}, respectively (\cref{fig:vd}).  \tmat{R} is estimated from the SNP genotypes of the samples and captures the kinship of the samples, while the noise sample-to-sample covariance is assumed to be constant. The variance decompositon (VD) of \tmat{Y} into \tmat{G} and \tmat{\Psi} is achieved by estimating \tmatsub{C}{g} and \tmatsub{C}{n} via restricted marginal likelihood (REML). The complexity of the VD is \(O(N^2 + t(NP^2 + NP^4))\) with \(N\) the number of samples, \(P\) the number of traits, and \(t\) the number of iterations of Broyden's method for optimising the REML of the parameter estimates. From this equation, it becomes evident that as the number of traits increases, the complexity increases by a power of four and explains why this LMM set-up is not feasable for large trait sets. To overcome the bottleneck of estimating the trait-to-trait covariance matrices as a whole which is the reason for the complexity of \(P^4\), I developed a simple method that efficiently uses a linear mixed model bootstrapping (LiMMBo) approach to estimate \tmatsub{C}{g} and \tmatsub{C}{n}.