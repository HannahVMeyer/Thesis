\chapter{Introduction}
The field of quantitative genetics has come far since Fisher's initial studies on growth traits in wheat in 1918. While back then the concept of inheritance existed, little was known about the molecule responsible. The discovery of the DNA structure by Franklin, Watson and Crick and technical break-throughs in analysing its sequence some 20 years later, have allowed to investigate genetic variance on a much more detailed scale, moving from whole chromosomes and linkage studies to the analysis of DNA variation on a single-base pair level. 

The developments in genotyping and sequencing technologies in the recent years have made large scale studies on genetic variation feasible. With the sinking costs of genotyping techniques, the number of samples investigated has risen and studies investigating the effects of single DNA bases often comprise thousands of individuals, especially in the field of human genetics.  Together with the increased number of samples available in these studies, the number of phenotypes that are measured for each individual has grown from a few measurements to tens or even hundreds. The availability of these rich datasets provides great opportunities when studying the influence of genetic variation on phenotypic variance, such as studying pleiotropy and complex trait structure. However, it also poses technical challenges in analysing these dataset. 

\section{From ancient ideas of inheritance to the birth of modern genetics}
The formulation of the concept of human inheritance --the passing on of traits from parents to offspring-- can be found as early as 400 B.C. in works by ancient greek philosophers. While Aristotle proposed the inheritance of acquired traits in \textit{Generation of animals}, Hippocrates and Democritus describe a possible meachanism of inheritance \citep{Zirkle1935}, a concept later formalised as `pangenesis' by the English naturalist Charles Darwin \citep{Darwin1868} and others such as the French Comte de Buffon \citep{Buffon1749} and Genevan naturalist Charles Bonnet \citep{Bonnet1781}. The theory of pangenesis -- which translates to whole (greek: pan) origin (greek: genesis) or birth (greek: genos) -- describes how the entire parental organism participates in passing on traits to the offspring. 

Before hypothesing about the mechanism of inheritance, Darwin had published his ideas about trait variation and the link to inheritance in his famous work \textit{On the Origin of Species} \citep{Darwin1859}, postulating natural selection as the central concept of evolution. In this work, he described his observations of phenotypic variance in a population, the differential fitness they may confer and the concept of heritability of this fitness \citep{Lewontin1970}. While these general concepts are still accepted today, the mechanism of inheritance via pangenesis has clearly been refuted. 

\subsection{Mendel's Laws of Inheritance}
The Austrian friar Gregor Mendel was the first to systematically study the mechanisms of heritability on hybrids of pea plants and he published his experiments as \textit{Versuche ueber Pflanzenhybride} in 1966. He proposes three general concepts of inheritance which later became known as the Mendelian Laws of Inheritance: i) the Law of Independent Segregation (every individual contains two alleles for each trait and they segregate in germ cells leading to a random transmission of alleles to the offspring), ii) the Law of Independent Assortment (traits are inherited independently from one another) and iii) the Law of Dominance (recessive alleles will be masked by dominant alleles and the trait corresponding to the dominant allele will be observed). Although his work stayed widely unnoticed during his lifetime, his meticulous studies and documentation ensured his recognition as the father of genetics when his work was independently rediscovered in 1900 by the Dutch  botanist Hugo de Vries \citep{deVries1900,Hannah1950}, the German botanist Carl Correns \citep{Correns1900,Pierncik1950} and --although contested by some based on a seeming lack in understanding the Mendelian concepts of heritability \citep{Monaghan1986,Floyd1987}-- the Austrian agronomist Erich Tschermak \citet{Tschermak1900}. 

In parallel to the experimental and observational work in plant hybrids, two other branches of investigations contributed to the increasingly popular work on Mendelianism and the identification of the molecular basis of the Laws of Inheritance from 1900 onwards: mathematical models and molecular biology. 

\subsection{First statistical approaches for the analysing inheritance}
In 1968, Francis Galton published the \textit{Regression Towards Mediocrity in Hereditary Stature} offering a statistcial approach towards understanding inheritance. Based on measurements of height in parents and their children, he observed that the `[t]he height-deviate of the offspring is, on the average, two-thirds of the height-deviate of its mid-parentage'. He achieved the quantification of the deviation from the mean as two-thirds by fitting straight lines to the observed heights and finding their slope, thereby developing the technique of linear regression analysis \citep{Tschermak1900}. Similarily, \citet{Pearson1900,Pearson1901} extended the statistical models for quantifying the effects of inheritance on trait variance by introducing the concept of p-values, the Chi-sqare test and principal component analysis. 

\subsection{A first glimpse at the molecul conferring ineritance}
Advances in understanding the molecules responsible for inheritance were made by the Swiss physican and biologist Johannes Miescher and the German anatomist Walther Flemming. Both were interested in the structure of the nucleus investigated human lymphocyte and salamander nuclei for their composition. Miescher was the first to successfully isolate 
a substance he called \textit{nuclein} --later known as DNA-- from the nucleus \citep{Miescher1971}. Flemming's investigation of the structure of the cells lead to the discovery of structure that could easily be stained by basophilic dies and named this structure \textit{chromatin} --  `coloured material` (greek:khr≈çmat). He later found chromatin to be originating from the cell nucleus and did further studies into understanding cell division and mitosis \citep{Flemming1978}. Although, both Miescher and Flemming's methods and discoveries were crucial in the indentification of DNA as the `carrier of inheritance', neither of them made this connection at that time. 

With these advances in molecular and statistical techniques and the rediscovery of the Mendelian laws the new discipline of genetical research attracted much attention. The  milestones in genetics made since Darwin's work \textit{On the Origin of Species} the birth of modern genetics founded in Mendel's Laws as well as statistical models and techniques in molecular biology that enabled the analysis and made these discoveries possible are depicted in \cref{fig:timeline-genetics}.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Introduction/Figures/TimelineQuantGenetics.pdf}
	\caption[\textbf{Genetics over time. }]{\textbf{Genetics over time. } The developments in genetics from its birth by Mendel's Laws of Inheritance to large databases cataloguing genetic variation of thousands of individuals are depicted in the lower panel. Statistical concepts and techniques in molecular biology crucial for the advances in genetics are depicted in the upper and middle panel respectively. Whilst there are many independent studies in all three areas contributing to the successes in genetics that we observe today, I tried to depict all major events that lead to the specific field of human quantitative genetics in GWAS era. The legend below the timelines specifies the symbols of the organisms used in the respective studies. As references for each entry, the first author of the corresponding publication is shown. Discoveries where multiple authors are named indicate independent studies at the same making the same discovery/developing techniques. } 
	 	\label{fig:timeline-genetics}
\end{figure}

\section{The Laws of Inheritance on a cellular level}
The first two scientists proposing a how Mendel's Laws could work on a cellular level were the German biologist Theodor Boveri and the American Walter Sutton. By experimentally introduced double-feritlisations of sea urchin eggs and subsequent overservations of developmental processes in the resulting embryos, Boveri claimed `[t]hat a specific combination of chromosomes is necessary for a normal development which in turn means that each chromosome must harbour different qualities' (translated from German). At the same time, Sutton described his observations in reduction division (later known as meiosis) and postulates that different chromosomes play different roles in development. Similar to Boveri, he came to the conclusion that `[t]he phenomena of germ cell division and of heredity are seen to have the same essential features [...], with purity of units (chromosomes, characters) and the independent transmission of the same \citep{Sutton1903}. Both studies demonstrated the link between the Mendelian Laws of inheritance and chromosomes as confering this inheritance and are the basis for the chromosome theory of inheritance also known as Boveri-Sutton Chromosome theory. 

With the progress in understanding Mendelian laws on a cellular level came the establishment of terms describing certain entities and properties still in use today. The British geneticist William Bateson, a strong proponent of Mendel's work, became known for coining key terms in the field of genetics, even the term `genetics' itself \citep{Dunwell2007}. He defined the units of inheritance transmission as `allelomorphs`, which became later abbreviated as alleles and introduced the terms homozygote and heterozygote for individulas carrying the same or different allelomorphs \citep{Bateson1902}. The word `gene' as a term for the Mendelian factors or units of inheritance was introduced by the danish botanist Wilhelm Johannson \citep{Johannsen1911}. He also introduced the terms `phenotype' as a the outward appearance of and individual and `genotype' as its genetic traits. While these terms are standard in today's field of genetics, their use in that time only rose slowly over time. For simplicity, however, I will from now on refer to any description of Mendelian fators or units as genes. 

Apart from introducing terminoloy, Bateson worked together with Edith Saunders and Reginald Punnett on experiments similar to Mendel's pea hybrids, discovering traits whose segregation did not follow the Law of independent Assortment. These observation lead them to propose the concept of coupling or co-inheritance of some traits \citep{Bateson1905}. 

\section{Genetic linkage}
The American embryologist Thomas Morgan was critical of the ideas of Mendelian inheritance and chromosomes as its carrier \citep{Allen1968}, yet he should become a crucial figure in establishing the chromsomal theory of heredity and the introduction other important concepts of inheritance. In his famous Fly Room at Columbia University, he worked on mutation and breeding experiments in the fruit fly \textit{Drosophila Melanogaster} aiming to discover mutation that would lead to the emergence of new species, a mechanism described by DeVries \citep{Allen1968}. Instead, his experiments on fruit flies mutants for eye color (white instead of red) showed that the pattern of inheritance of the mutant trait followed the Mendelian Law of Dominance. In addition, he discovered that the factor determining eye color was linked to the factor for the sex determination \citep{Morgan1910,Morgan1911a} pointing towards the coupling of traits as observed by Bateson.

In subsequent years, Morgan and his students carried out extensive research on mutant fruit flies which lead to the discovery of crossing over (exchange of paternal and maternal chromsomal material during Meiosis) and the formalisation of the concept of genetic linkage \citep{Morgan1911b}. Based on the hypothesis that the degree of linkage between phenotypes would be inversely correlated to the linear distance of their genes on a chromosome, they developed the technique of genetic mapping: the localization of genes underlying phenotypes on the basis of correlation with inheritance patterns [DNA variation], without the need for prior hypotheses about biological function \citep{Altshuler2008}.

Using this technique where the recombination rate between traits is used to estimate the relative distance of their genes, his student Alfred Sturtevan published the first genetic map describing the order of genes on the X chromosome of \textit{Drosophila Melanogaster} in 1913 \citep{Sturtevan1913}. Together with two Morgan's students Herman Muller and Calvin Bridges they pushlished their book on \textit{The Mechansim of Mendelian Heridity}\citep{Morgan2015}. Herein, they describe additional genetic maps for chromsome 2 and 3 and list groups of genes that are inherated jointly. The inheritance pattern of the genes was determined by genetic linkage, where they mapped mutant genes to the phenotypes they induced, such as \textit{vestigial} (vestigial wings), \textit{eyeless} and \textit{white} (white eyes as compared to the standard red eyes). 

Initially, Morgan had attempted to induce mutations in Drosophila through a range of different conditions e.g temperature and acids and radium/X-rays \citep{Sturtevant1959}. His first successful mutations in fly with radium gave rise to flies with `beaded wings' and subsequent additional phenotypes observed when cross-breeding lines \citep{Morgan1911c}, similarly the range of eye mutant Drosophila lines were generated \citep{Morgan1911d}. Muller set out to find a more efficient way of introducing mutations and discovered X-rays as a strong mutagenic, enabling him to induce `several hundred mutations [...] in a short time` \citep{Muller1927} and helped to considerably speed up of generation new lines to carry out genetic mapping. 

%In 1933 and 1946, Morgan and Muller were independently awarded with a Nobel Prize in Medicine `for discoveries concerning the role played by the chromosome in heredity' and `for the discovery of the production of mutations by means of X-ray irradiation'. 

\section{Towards quantitative genetics}
With their development of genetic mapping and cross-breeding of Drosophila lines, Morgan, Sturtevant, Muller and Bridges conducted the first genotype-phenotype analysis studies. As in Mendel's original experiments and later, similar work by Bateson, Saunders and Punett, the phenotypes they observed were predominantly categorical, such as color of seed and flower in pea plants or the eyeless phenotype in Drosophila. A great advance in genotype associations allowing for their evalution in a quantitative manner came about with the work by the British statistician and biologist Ronald Aylmer Fisher. 

An undergraduate student at the University in Cambridge, Fisher published his first paper on a criterion for fitting frequency curves where he outlined the fundamental ideas of maximum likelihood estimation \citep{Fisher1902}. He later extended on this work and by 1922, he had established the properties of the maximum likelihood estimator such as consistency and minimum variability \citep{Fisher1922a} that is still used today \citep{Hald1999}. He demonstrated the utility of maximum likelihood estimation in genetics by solving a number of equations to elucidate a genetic map of eight Drosophila genes based on their crossing over frequencies \citep{Fisher1922b}. In the same year and years to follow, he published a series of papers where he derived the distribution and signficance testing of regression coefficients, correlation ratios and multiple regression coefficients \citep{Fisher1922c,Fisher1928}, an exact test for two-by-two contingency tables with small expectations (Fisher's exact test) \citep{Fisher1922d}, partial correlation coefficients \citep{Fisher1924a} and the variance ratio later named after Fisher as the F statitistic \citep{Fisher1924b}. 

The cornerstone for quantitative genetics was laid with his 1918 publication \textit{The correlation between relatives on the supposition of Mendelian inheritance} where he showed that biometrics  and Mendelianism are not contradictory but complimentary. Specifically, by analysing levels of phenotypic correlation between individuals of differing degrees of relatedness, he showed that the observed phenotypic variation can result from Mendelian inheritance. As an additional statistical concept, it was in this work that he defined the term `variance` as `the square root of the mean squared error'. The analysis of variance in biological experiments would be of interest to Fisher in his following appointment at Rothampsted Experimental Station where he analysed data from crop experiments with respect to different variance components and developed statistical techniques such as the analysis of variance (ANOVA) \citep{Fisher1921,Fisher1923,Eden1929}. 

Finally, Fisher can also be attributed with the reconcilation of the long-standing ideas of Darwins evolutionary theory and Mendelian inheritance. In his book \textit{The Genetical Theory of Natural Selection} he gives the first, comprehensive quantitative theory of sexual selection, evolution of recombination rates, and polymorphism and many more concepts found in today's field of population genetics. 

\section{Progress in deciperhing the molecular mechanisms of inheritance}
A large step foward in the molecular understanding of inheritance was the discovery of DNA as the genetic material \citep{Avery1944} and the resolution of the DNA structure almost a decade later \citep{Watson1953}. The information of the chemical composition of DNA from the four bases adenine, thymin, cytosin and guanine brought forward an understanding of other biological concepts such as protein synthesis and enabled Francis Crick to postulate the central dogma of biology:  Information is transmitted from DNA and RNA to proteins, but information cannot be transmitted from a protein to DNA \citep{Crick1958}. The deciphering of the genetic code through Nirenberg and other followed a few years later \citep{Nirenberg1961,Crick1961,Matthaei1962}.  

\subsection{Novel genotype mapping techniques}
Three discoveries and novel techniques at the beginning of the 1970's opened the door for the development of new genetic mapping approaches: the discovery of restriction enzymes \citep{Smith1970,Morrow1972}, the ability to clone and amplify specific DNA sequences \citep{Jackson1972,Cohen1973}, and the detection of specific DNA sequences from a large pool of DNA fragments (Southern plot) \citep{Southern1975}. Based on these techniques, restriction fragment length polymorphism (RFLP) analysis was developed, which allows for the identification of variants from within a specific genomic region using restriction enzyme-digested DNA \citep{Grodzicker1974,Botstein1980}. Initially, these RFLP anaylsis was used for genetic linkage maps in model organisms \citep{Goodman1977,Cameron1979} and target genes in human  \citep{Kan1978,Jeffreys1979,Tuan1979}.  Based on theoretical considerations of using RFLP analysis for a general, target-free genetic mapping in humans \citep{Botstein1980}, the first genetic map in humans was published in 1987 \citep{Donis-Keller1987}. 

\subsection{Deciphering DNA sequences}
While these mapping efforts where underway, the independent development of two different DNA sequencing techniques by Frederik Sanger and Walter Gilbert together with Allan Maxwell were a further big leap in understanding the biological basis of genetic variation. Sanger's method of DNA sequencing with chain-terminating inhibitors eventually became the standard for DNA sequencing and subsequent innovations lead to the development of automatic sequencing machines \citep{Hunkapiller1991}. Based on Sanger sequencing, a novel strategy --shotgun sequencing-- for the design of the DNA fragments to be sequenced was developed \citep{Staden1979,Anderson1981}, allowing to determine the sequence of DNA fragments longer than the possible sequence length of approximately one kilobase.  In shotgun sequencing, the long DNA of interst is randomly broken up into shorter DNA fragments which are cloned and sequenced separately. The occurrence of overlapping DNA fragments given by the random nature of creating the short fragments allows for the \textit{in silico} reconstruction of longer DNA fragments based on the overlapping sequences. 

In 1995, the first genome of a living organis --the bacteria \textit{Haemophilus influenzae} was sequenced and assembled by shotgun sequencing \citep{Fleischmann1995}. The genomes of other model organims were to follow in subsequent years (yeast \citep{Goffeau1996}, \textit{C. elegans} \citep{C.elegans1998}, \textit{D. melanogaster} \citep{Adams2000}) until the first draft of the human genome was published in 2000 \citep{Lander2000}. 

The sequence of the human genome, the development of faster, massively-parallel next-generation sequencing techniques (reviewed in \citep{Shendure2008,Heather2016}) and DNA microarrays that allow for the genotyping of hundreds of thousands of genetic markers simultaneously \citep{Wang1998}, started a new era of human genetic and genomic research. 

\section{From genetic linkage analysis to genome-wide association studies}
\subsection{Genetic association studies until the 1990s}
Initially, genotype to phenotype mapping in humans was restricted to pedigree-based linkage analysis \citep{Bernstein1930,Haldane1934,Penrose1935} of single candidate genes such as haemoglobin \citep{Ingram1959} and blood antigens \citep{Bernstein1930,Haldane1934,Penrose1935}. In the 1950ies,  an alternative type for genetic association in humans was introduced. In population-based association study,  the frequencies of the genetic markers are compared in carriers (case) and non-carriers (controls) of the phenotype under investigation. If the frequency of the markers are increased in cases compared to controls, the genetic marker as thought to be associated with the risk for diseases. Often, the significance of the association is evaluated via a simple \(\chi ^2\)-test, as was done in the population association study for blood antigens and stomach cancer \citep{Aird1953,Aird1954}. In subsequent years, both population association studies and genetic linkage helped discover genetic association on population (e.g. with diastrophic dysplasia \citep{H√§stbacka1992} and alzheimers' disease as reviewed in citep{Strittmatter1996}) and family-level (with e.g. Huntington disease \citep{Gusella1983}, cystic fibrosis \citep{Kerem1989} and bipolar disorder \citep{Baron1987}), respectively . However, phenotypes associated on population level only provide an indirect link to genetic linkage \citep{Cox1988,Spielman1993} and might be subject to population stratification. In 1993, Spielman and colleages reconciled both approaches, by formally introducing the transmission/disequilibrium test which test directly for linkage between a disease and marker locus which shows population association. Notably, the transmission/disequilibrium test is not affected by population stratification \citep{Spielman1993}.An extension of the population-association model to multiple, quantitative traits was provided by Jiang and colleagues in 1995. They introduced a linear model framework were multiple traits are jointly analysed for genetic association, testing different models such as pleiotropic effects, and gene-environment interaction \citep{Jiang1995}. 

\subsection{`Common disease‚Äìcommon variant' hypothesis}
By the mid-1990s, genotype-phenotype mapping in humans was still largely focused on candidate gene mapping and had so far detected about 250 genes associated with disease or dichotomous traits \citep{Hirschhorn2002}. However, the number of reproducable results was significantly lower and showed the difficulties associated with case-control population association studies. Major limitation were seen in the susceptibilty to population stratification \citep{Lohmuller2003} and the low \textit{a priori} probabilty of the tested genetic variants to be causal. In addition, for illnesses such as heart disease, diabetes or hypertension, the risk of being affetced is likely a combination of multiple genetic and environmental factors \citep{Hunter2005}, which stands in stark contrast to pattern observed in monogenic disaeses. Here, the presence of a genetic factor (dominant) or factors (recessive) completely predicts presence of disease such as cystic fibrosis or Huntington's Disease and these factors are generally of low frequency \citep{Sankaranarayanan1998}.  In the complex diseases, the genetic risk factor may be present in high frequency and only lead to a small increase in risk for the disease \citep{Reich2001}. Based on these arguments, the `common disease‚Äìcommon variant' hypothesis had been proposed, stating that common polymorphisms may play a role to the susceptibility to common diseases \citep{Risch1996,Lander1996,Chakravarti1999,Reich2001}. In order to  detect these common disease variants on a genome-wide level, three components are needed: a catalogue of common variants in the human population, experimental techniques to obtain these genotypes in large cohorts and the computational techniques for the subsequent analysis.

\subsection{Databases of human variation}
\label{subsection:databases}
The first genome-wide database of common human sequence variation was created within the scope of the International HapMap project which was launched in 2002 \citep{HapMap2005,HapMap2007,HapMap2010}.
The HapMap project aimed at characterizing the frequencies of single nulceotide polymorphism (SNP), variation on a single base pair level, for different human populations. Based on their genome-wide SNP frequencies, a comprehensive map for linkage disequilbrium (LD) --the nonrandom association of alleles at different loci \citep{Lewontin1960}-- in different populations was created. By having included parent‚Äìoffspring trios in the anaylsis, computational phasing techniques such as PHASE \citep{Stephens2001} or SHAPEIT \citep{Delaneau2012,Delaneau2013} (reviewed in \citep{Browning2011}) enabled to determine the SNP contribution from each parent and the combination in which they were inherited. This particular combination of SNPs along a chromosome is termed haplotype and was name-lending for the database. The HapMap collection contains 1.6 million common single nucleotide polymorphisms in \num{1184} reference individuals from 11 global populations. An extension of the work of the HapMap project, the 1000 Genome Project aimed to detect common human genetic variation by whole-genome sequencing to individuals from multiple populations. The project finished in 2015, providing genotypes and haplotypes at more than 88 million variants, including SNPs, short insertions or deletions (indels), and structural variants for 2,504 individuals from 26 populations \citep{1000Genomes2011,1000Genomes2012,1000Genomes2015}. The work of the UK10K consortium complemented the work of both previous projects and extends the spectrum of observed genetic variation to rare variants in nearly \num{10000} individuals from population-based and disease collections \citep{UK10KConsortium2015}. While the major focus of these consortia layed in the collection of comprehensive genotype data, a novel resource combining both genotype and phenotype data of more than \num{500000} individuals has recently been published. Phenotypes collected within this resource, the UK Biobank, cover amongst others anthropometric, cardiac and disease phenotypes \citep{Sudlow2015}.

\subsection{Genotyping of large cohorts}
Genotype data of common variants is standardly obtained from DNA microarrays which allow for the genotyping of hundreds of thousands of common SNPs simultaneously \citep{Wang1998}. 
Based on the LD structures found in the reference panels (described above), haplotypes of the individuals can be estimated. Comparing the estimated haplotypes of the individuals to haplotype patterns in the reference panel enables to predict unobserved genotypes in the study cohort. This technique is refered to as imputation and a number of different methods have been developed including IMPUTE2 \citep{Howie2009}, Beagle \citep{Browning2007} and MaCH \citep{Li2010} (reviewed in \citep{Marchini2010}). Via imputation, the number of genotypes per individual can be extended from the hundred thousands on the genotyping chip to millions of observed variants in the reference datasets. Using these extended genotypes for assocication studies can increase the power of the study and presents a high-resolution view of all SNPs in the associated region \citep{Marchini2010}.

\subsection{Genome-wide association studies}
\label{subsection:GWAS}
The first successful study to test the `common disease‚Äìcommon variant' hypothesis without gene-based selection of genetic markers was conducted in 2005. Klein and collegues carried out a case-control association study across all genome-wide SNPs (GWAS) for age-related macular degeneration and found a SNP in complement factor H to be associated with an increase in disease-risk \citep{Klein2005}. Similar to population association studies of candidate genes, the significance of each SNP-disease association was tested via a \(\chi ^2\)-test and the resulting p-values subsequently corrected for multiple testing via Bonferroni correction (see \cref{subsection:multiple-testing}. Soon after, the Wellcome-Trust case-control consortium (WTCCC) published GWAS carried out on \num{2000} samples and \num{3000} controls for seven common diseases, including bipolar disorder, coronary heart disease and type I and II diabetes \citep{Burton2007}. In the same year, the first GWAS on a quantitative traits followed. Two research groups investigated the genetic effects on body mass index and found links to the FTO gene. In addition, these BMI-associated SNPs also showed strong association to type II diabetes \citep{Frayling2007} and other SNPs within the FTO gene were also associated to weight and hip-circumference \citep{Scuteri2007}. Both studies used a simple linear model  (see \cref{section:LinearModels}) to find the association of the genetic marker as the explanatory variable and BMI as response variable. 

Since then, thousands of GWAS have been conducted covering common diseases (e.g. asthma \citep{Noguchi201,Pickrell2016}, coronary heart disease \citep{Wild2011,Takeuchi2011,Lu2012}, migraine \citep{Pickrell2016,Gormley2016}, blood pressure \citep{Kato2011,Franceschini2013}), anthropometric traits (height \citep{Lango2010,Wood2014}, weight \citep{Willer2008}, BMI \citep{Speliotes2010,Yang2012}, waist-hip ratio \citep{Lindgren2009,Heid2010}) and other non-disease related quantitative phenotypes (e.g. eye color \citep{Erikson2010,Candille2012,Zhang2013}, freckling \citep{Sulem2008}, facial morphology \citep{Paternoster2012}, hair greying \citep{Adhikari2016}). The results of these studies are collected in the GWAS catalogue, which currently contains \num{3092} publications and \num{49769} unique SNP-trait associations (accessed 10.09.2017; \citep{MacArthur2017}). 


\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Introduction/Figures/GenotypePhenotype.pdf}
	\caption[\textbf{Genotype-phenotype mapping approaches. }]{\textbf{Genotype-phenotype mapping approaches. } \red{I made this figure when staring with the introducation, but not sure if needed or even fitting anymore, since I don't talk much about anything else than GWAS...}} 
	 	\label{fig:genotype-phenotype}
\end{figure}


%`[a] knowledge of sequences could contribute much to our understanding of living matter' Sanger \citep{Nobel1981}. 

%
 %

%irst quantitative GWAS: Framingham Heart study, generalised estimation equations, 


\subsection{Challenges in genome-wide association studies}
Analysis of genetic data of \num{1000} of individuals on a genome-wide level offers a hypothesis-free, data-driven approach to detect genotype-phenotype associatons. However, the genetic structure of the sample cohort and the large number of tests conducted pose challenges for design and evaluation of the statistical analysis. 

\subsection{Correcting for multiple hypothesis testing in GWAS}
Refers to the problem that arises when many null hypotheses are tested; some significant results are likely even if all the hypotheses are false
\label{subsection:multiple-testing}

\paragraph{False discovery rate}

\paragraph{Family-wise error rate}

\paragraph{LD-corrected genome-wide significance threshold}
The common GWAS significance threshold is based on the number of independent variants in the genome. It was first proposed in the scope of the HapMap project \citeyear{HapMap2005} which found about \num{150} independent, common variants per \num{500}~kb region. At a significance threshold of \(p < 0.05\) and extrapolated to the genome size of \(\sim 3.3\)~Gb, by Bonferroni correction this yields  \(0.05/(\frac{150}{500\text{kb}} \times 3.3 \text{Gb}= 5.05 \times 10^{-8}\). This estimate was later confirmed in a study using different methods for estimating the number of independent variants \citep{Fadista2016}.

\subsection{Relatedness and population structure}
between the SNP and a locus that is involved in disease causation. The most important spurious cause of an association is population structure.
Population
This problem arises when
cases disproportionately represent a genetic subgroup (population 1 in the figure), so that any SNP with allele proportions that differ between the subgroup and the general population will be associated with case or control status. In the figure, the blue allele is overrepresented among cases but only because it is more frequent in population 1. Some overrepresented SNP alleles might actually be causal (the blue allele could be
the reason that there are more cases in population 1), but these are likely to be ‚Äòswamped‚Äô among significant test results by the many SNPs that have no causal role. If the population strata are identified they can be adjusted for in the analysis102

Cryptic population structure that is not recognized by investigators is potentially
more problematic, although the extent to which it is a genuine cause of false positives has been the topic of much debate13,49,103,104
There are at least three reasons for a
subgroup to be overrepresented among cases: Higher proportion of a causal SNP allele in the subgroup;
Higher penetrance of the causal genotype(s) in the subgroup because of a different environment (for example, diet);
Ascertainment bias (for example, the subgroup is more closely monitored by hea




\section{Models for genome-wide association studies}
\label{section:LinearModels}

by assuming a linear relationship between mean value of the trait and genotype (FIG. 3). In either case, tests require the trait to be approximately normally distributed for each geno- type, with a common variance. If normality does not hold, a transformation (for example, log) of the original trait values might lead to approximate normality.


In genotype to phenotype mapping, the most simple linear model (LM) describes the linear relationship between a phenotype \(y\) and a genetic marker \(x\). Optionally, known covariates \(F\) can be included as explanatory variables. There are a variety of different types of models, depending on the structure of background effects and the number of phenotypes that are modeled simultaneously. In the following, a short description of the models relevant for this project is outlined. 

\subsection{Simple linear model for genotype associations with a single trait}
\label{subsection:lm-uv}
The uni-variate LM models a single phenotype \(y\) as the sum of a fixed effect of the genetic marker \(x\) and \(K\) known covariates \(F\) and residual noise \(\psi\) across \(N\) samples:

\begin{equation}
\mat{y} = \mat{F}\mat{\alpha} + \mat{x}mat{\beta} + \mat{\psi},\text{ }
\mat{\psi} \sim \normal 0 {\sigma_e^2\matsub{I}{N}}.
\label{eq:lm-uv}
\end{equation}

with
\begin{align*} 
& \text{the phenotype vector } \mat{y} \inR N 1,\\
& \text{the matrix of $K$ covariates }\mat{F} \inR N K,\\
& \text{the effect of covariates } \mat{\alpha} \inR K 1,\\
& \text{the genetic profile of the SNP being tested }\mat{x} \inR N 1 \text{and}\\
& \text{the effect size of the SNP } \mat{\beta} \inR x x \\
\end{align*} 


\noindent The association between phenotypes and the genetic markers can be assesed by testing the hypothesis that the genetic variant has an effect \(\beta \neq 0\) versus having no effect on the phenotype. The log likelihood ratio (LLR) test statistic \(\Lambda\) is a commonly used statistic to compare the likelihood of the full model \taltH (Equation~\ref{eq:lm-uv}) with \(\beta \neq 0\) to the one of the Null model \tnullH:
\begin{equation}
\nullH: \mat{y} =\mat{F}\mat{\alpha}  + \mat{\psi},\text{ }
\mat{\psi}\sim \normal 0 {\sigma_e^2\matsub{I}{N}}
\label{eq:lm_null}
\end{equation}

\noindent The LLR test statistic \(\Lambda\) is defined as
\begin{equation}
\Lambda  =  \mathcal{L} (\hat{\beta}, \hat{\alpha}, \hat{\sigma_{e}}) -  \mathcal{L} (0, \hat{\alpha}, \hat{\sigma_{e}})
\label{eq:llr}
\end{equation}

\noindent where \(\mathcal{L} (\hat{\beta}, \hat{\alpha}, \hat{\sigma_{e}})\) are the maximum likelihood estimators (MLE) of  \taltH and \(\mathcal{L} (0, \hat{\alpha}, \hat{\sigma_{e}})\) the MLE of \tnullH. 

\noindent \(2\Lambda\) follows a \(\chi^2_{df}\) distribution with \(df\) degrees of freedom \citep{Wilks1938} 
\begin{equation}
2\Lambda \sim \chi^2_{df} 
\label{eq:lambda}
\end{equation}

\noindent and allows for the calculation of the P value as :
\begin{equation}
P(\Lambda) = 1 - F_{\chi^2}(2\Lambda, df)
\label{eq:pvalue}
\end{equation}

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Introduction/Figures/GWASstats.pdf}
	\caption[\textbf{.}]{\textbf{.} } 
	 	\label{fig:GWAs-stats}
\end{figure}

\subsection{Adjusting for population structure and genetic kinship}
Fixed genetic background componts are standardly modeled via principal components (PCs) of genotype data \citep{Price2006} and have been shown to adjust well for population structure based on ancestry differences \citep{Patterson2006}. However, PCs perform poorly in modeling family structure or cryptic relatedness.  By modeling genetic background as a random effect, more complex covariance structures can be used such that correlations in phenotype reflect family structure and relatedness \citep{Yu2006,Kang2008}.
	
Pruning for LD structure to construct kinship matrices \citep{Eu-ahsunthornwattana2014}
Derivation of kinship matrix as  \(\frac{1}{7}\) \citep{Speed2012}
	

Under Hardy-Weinberg:
allele frequencies: 
\begin{equation}
p + q =1
\end{equation} 

genotype frequencies: 
\begin{equation}
p^2 + 2pq + q^2 = 1
\end{equation} 

additive genotype encoding, allele dosages: 
\(d(a_{alt},a_{alt}) = 0\) 
\(d(a_{alt},a_{ref}) = 1\) 
\(d(a_{ref},a_{ref}) = 2\) 

Expected genotype per SNP: 
\begin{equation}
E(x) =  d(a_{alt},a_{alt}) \times p^2 + d(a_{alt},a_{ref}) \times 2pq + d(a_{ref},a_{ref}) \times  q^2)
E(x) = 2pq + 2q^2 = 2(1-q)q + 2q^2 = 2q 
\end{equation}

Variance and standard deviation of genotype per SNP: 
\begin{equation}
Var(x) = E(x^2) - E(x)^2 = d(a_{alt},a_{alt})^2 \times  p^2 + d(a_{alt},a_{ref})^2  \times 2pq + d(a_{ref},a_{ref})^2  \times q^2 - (2q)^2 =  2q(1-q)
\end{equation}

\begin{equation}
\sigma(x) = \sqrt(Var(x)) = \sqrt(2q(1-q))
\end{equation}

standardised genotypes:
\(x_{SNP} = \frac{x_{SNP}-2q_{SNP}}{\sqrt{2q_{SNP}(1-q_{SNP})}}\)



\subsection{Extending the simple linear model: linear mixed models in genotype to phenotype mapping}
\label{subection:lmm}
Linear mixed models (LMMs) include both fixed and random effects in the model. In genetics, LMMs can model both fixed genetics effects, i.e. single variants, and background genetic effects, i.e. controling for population structure and accounting for polygenic background \citep{Yu2006}. Population structure and relatedness between individuals can be captured in a genetic relatedness matrix, which accounts for the pairwise genetic similarity between individuals. The relatedness matrix is estimated as
 \begin{equation}
 R = \frac{1}{S}XX^T
 \label{eq:relatedness}
 \end{equation}
 where \(S\) is the number of SNPs used for the estimation and \(X\) is the \(S \times N\) genotype matrix. As described for the linear model, there are uni-variate and multi-variate LMM set-ups for genetic association analyses. 

The genetic background and residual noise are modeled as random effects with a scalar MLE for the genetic \(g\) and noise trait-variance \(\psi\),   \(\sigma_g^2\) and \(\sigma_e^2\):

\begin{equation}
\mat{y} =\mat{F}\mat{\alpha} +\mat{x}\beta +\mat{g}+\mat{\psi},\text{ }
\mat{g} \sim \normal 0 {\sigma_g^2\mat{R}},\text{ }
\mat{\psi} \sim\normal 0 {\sigma_e^2\mat{I}_N}
\label{eq:lmm-uv}
\end{equation}

with
\begin{align*} 
& \text{the phenotype vector }\mat{y} \inR N 1,\\
& \text{the matrix of $K$ covariates }\mat{F} \inR N K,\\
& \text{the effect of covariates } \mat{\alpha} \inR K 1,\\
& \text{the genetic profile of the SNP being tested }\mat{x} \inR N 1,\\
& \text{the effect size of the SNP } \mat{\beta} \inR x x \text{ and}\\
& \text{the sample relatedeness matrix }\mat{R} \inR N N,
\end{align*} 


\subsection{Joint analysis of multiple phenotypes}
Many cohort studies today, ranging from studies in model organism such as yeast and arabidopsis thaliana to human, have rich, high dimensional datasets including molecular, morphological or imaging derived traits \citep{Bloom2013,Atwell2010,Astle2009,Shaffer2016,Stein2010}. However, these traits have often been analysed separately,  partly for simplicity and partly because of a paucity of models suitable for the anlaysis of high-dimensional phenotype data. A variety of multi-trait models have been developed which can be broadly grouped into three different classes: i) dimensionality reduction techniques, ii) meta-analysis approaches and iii) multivariate regression models (reviewed in \citep{Shriner2012,Yang2012}). 

\paragraph{Dimensionality reduction techniques} Dimensionality reduction methods in genotype-phenotype mapping seek to find a linear combination of the phenotypes into a lower dimensional space. Two dimensionality reduction methods commonly used as a transformation for phenotypes are principal component analysis (PCA) and canonical correlation analyses (CCA). An overview of other methods and a more detailed description of methods in this section will be given in \cref{chapter:DimReduction}. 

In PCA, the phenotype data is projected into its principal components - the eigenvectors of the empirical covariance matrix. Principal components reflect the internal structure of the data in terms of the phenotypic variance that they explain: the highest amount of phenotypic variance explained lies in the first component, the second highest variance in the second component and so forth. The amount of variance that each component explains is given by its corresponding eigenvalue. The dimensionality reduction is achieved by using all those principal components (in increasing order) until the cumulative sum of the eigenvalues reaches a predefined threshold of total phenotypic variance that should be retained. PCA as a dimensionality reduction technique has for instance been used in studies to find links between genotypes and facial features or obesity phenotypes \citep{Liu2012,Claes2014,He2008}. Recently, Aschard and colleagues \ref{Aschard2014} demonstrated that simply focusing on the principal components with the highest variance might not exploit the full potential of using PCA for genetic association. They propose a model of combined PCA where the PCs are grouped based on the level of variance they explain. They show a power gain in detecting genetic associations compared to simple approaches of only testing the top few PCs.

While the PCA dimensionality reduction approach focus on the phenotype space and subsequent association with the genotypes, CCA finds the optimal linear transformation of the phenotypes while simultaneously testing for the association with the genotypes. Originally proposed by Hotelling for a general set of variables that remain invariant under internal linear transformation\citeyear{Hotelling1936}, in quantitative genetics CCA seeks to maximise the canonical (ordered) correlation  between the transformed phenotypes and genotypes. The transformation of the phenotypes and the maximal canonical correlation are found by eigendecomposition of a complex covariance term containing the empirical sample covariance matrices of the phenotypes and the genotypes as well as the cross-covariances of the phenotypes and genotypes. For a single genetic marker, CCA finds the linear phenotype transformation that explains the maximum amount covariance between this genotype and all traits and the eigenvector corresponding to the largest eigenvalue is used for transformation of the phenotypes \citep{Yang2102}. Ferreira and Purcell \citeyear{Ferreira2009} showed in simulations that CCA with multiple traits and one genetic marker controls well for type I errors and has increased power compared to multivariate tests. In order to extend CCA to more than one marker, the genotypes also have to undergo a linear transformation and the maximum canonical correlation is found by solving two eigenvalue problems. As the number of genotype markers in GWAS exceeds the number of samples, estimates of the genetype covariance term becomes unreliable \citep{Schaefer2005}. Several methods have been developed to circumvent this issue, making use of sparse matrices \citep{Parkhomenko2009} or a priori grouping of the genotypes \citep{Naylor2010}. 

\paragraph{Meta-analysis approaches} Meta-analysis approaches combine the simplicity of the univariate approaches with the advantages of the multivariate approach. For each phenotype, a univariate association study is conducted and the summary stastics of these tests combined. Many methods for combining the summary statistics \citep{Xu2003,Yang2010,Yang2012,Bolormaa2014} go back to the work by O'Brien \citep{O'Brien1984}, who proposed to use a linear combination of the observed test statistics for each univariate test \(\mat{T} =(T_1, \dots, T_P)^T\) as the new statistics to be evaluated for significance.  \tmat{T} is asymptoctically normal distributed with mean \(\mat{\mu} = (\mu_1,\ldots, \mu_P)^T\) and covariance matrix \(\mat{\Sigma}\). O'Brien stastistic allows for testing the Null hypothesis \(H_0: \mu = 0\) against the alternative hypothesis of  \(H_1: \mu_p \ge 0, p=1, \ldots , P \) and is most powerful if \(\mu_1= \ldots =\mu_P\) \citep{Xu2003}. It is defined as: \(S = \mat{J}^T \mat{\Sigma}\mat{T}\), with \(\mat{J} = (1, 1, \ldots, 1)^T\).  The statistic has been modified in a number of studies, by adapting either the weighting matrix \tmat{J}, the covariance matrix \tmat{\Sigma} or both. Xu and colleagues \citeyear{Xu2003} optimised \(S\) to allow for testing against a general \(\mu\) rather then for a case where  \(\mu_1= \ldots =\mu_P\) by allowing for flexible, but restrained weights in \tmat{J}. Similarily, Yang and colleagues  \citeyear{Yang2010} proposed non-uniform weights to reflect heterogeneity in the means and use a sample splitting and cross-validation approach to determine the optimal weights. 
While the previous two studies showed an increase in power for using the combined statistic, they either used a small marker set or small number of phenotypic traits.  Bolormaa and colleagues showed that these power gains also hold for genotype to phenotype mapping of 32 traits across all genome-wide markers \citep{Bolormaa2014}. In their study, the weights of O'Briens proposal are substituted by the signed t-statistic. 

\paragraph{Regression models} There are a number of different regression models that allow for the multivariate analysis of phenotypes. Among them are graphical models, generalized estimation equations and frailty models, for which a summary of methods and application can be found in \citep{Shriner2012,Yang2012}. Here, I will focus on describing the development of multivariate linear regression models for genotype-phenotype mapping. Before the era of GWAS, QTL mapping in linkage experiments have demonstrated the increase in power when jointly analysing traits with common underlying genetics. Jiang and colleagues \citeyearpar{Jiang1995} proposed a multi-trait model where the phenotypes are jointly modeled as the sum of the fixed genetic effects of interest, fixed effects for genetic background variation and residual noise. They show that the joint analysis of traits can increase power to detect the underlying genetics and can increase the precision of the parameter estimates. The significance of the association is determined via a likelihood ratio test of the parameter estimates under the Null model where the fixed genetic effect is zero and the parameter estimates under the alternative model. The alternative model design depends on the underlying biological hypothesis regarding the effect of the genetic variant. Here, Jiang and colleagues differentiate hyptheses for a simple joint mapping of phenotypes, pleiotrophy and gene-environment interactions. Joint mapping does not make any assumptions about the underlying genetic architecture and simply tests if an association can be found when both traits are analysed jointly, i.e. the effect of the genetic variant is non-zero for at least one of the traits. This hypothesis can be extended in requiring that the effect on both traits is unequal to zero. In this case, the genetic variant is considered to be pleiotrophic. To test for gene-environment interaction, the different conditions a trait was studied in can be treated as different traits and be jointly mapped. If the effect size estimates of the genetic variant are not equal, the variant is considered to have environmental interactions.  Methods developed thereafter often use the same underlying hypotheses for the mapping, but different techniques for the evaluation of the significance. For instance, two other groups developed methods for the joint analysis of traits based specifically on the residual sum of squares (RSS) matrix of the standard linear model (\cref{eq:lm}) estimated at each locus tested \citep{Knott2000,Korol2001}. In the model proposed by Knott and Haley, the different properties and descriptors of the RSS are used to determine the significance of the QTL mapping. To test for pleiotropy for instance, the determinent of the RSS at the test locus is compared to the RSS of the null model of no association. In contrast, Korol and colleagues propose to use the RSS of the multi-trait mapping as a means for trait transformation and dimensionality reduction. The resulting one-dimensional trait per sample is fitted in a single-trait test for significance testing.  While methods described so far have only used fixed genetic effects, Korte and colleagues \citeyear{Korte2012} were the first to introduce a random genetic effect into the model. Based on the original model by Jiang, they substituted the fixed effect accounting for background genetics by a random effect, turning the multivariate linear model into a mulitvariate linear mixed model (Equation~\ref{eq:lmm}). Based on these principals and method development for the efficient analysis of large cohort sizes, a number of publically available frameworks for the genome-wide mapping of a moderate number of traits via multivariate linear mixed models were developed. \citep{Korte2012,Yang2011,Lippert2014,Zhou2014,Casale2015}. 

Out of the differerent approaches described above, multivariate linear mixed models (LMMs) have the additional advantage that they can control for complex population structure and relatedness. 

\subsection{Linear models for the joint analysis of multiple phenotypes}
Extending the model to a multi-variate linear model, i.e. jointly modeling multiple phenotypes \(P\), requires the introduction of trait-design matrices for the fixed effects (\(\mat{A}\) and \(\mat{B}\) for the covariate and genetic effect respectively) and a trait-by-trait covariance matrix \tmatsub{C}{n} for the residual noise:
\begin{equation}
\mat{Y} =\mat{F}\mat{A}\matsub{W}{\alpha} +\mat{x}\mat{B}\matsub{W}{\beta} + \mat{\psi},\text{ }
\mat{\psi}\sim \multinormal N P 0 {\matsub{C}{n} \otimes\matsub{I}{N}}
\label{eq:lm-mv}
\end{equation}

with
\begin{align*} 
& \text{the Kronecker product } \otimes \\
& \text{the phenotype matrix }\mat{Y} \inR N P,\\
& \text{the matrix of $K$ covariates }\mat{F} \inR N K,\\
& \text{the effect of covariates } \mat{A} \inR K M,\\
& \text{the trait design matrix of the covariates }\matsub{W}{\alpha} \inR M P,\\
& \text{the genetype vector of the SNP being tested }\mat{x} \inR N 1\\
& \text{the effect size of the SNP } \mat{B} \inR 1 L \text{and}\\
& \text{the trait design matrix of the genotype }\matsub{W}{\beta} \inR L P,\\
\end{align*} 

The trait design matrices \(\mat{W}_{\alpha}\) and \(\mat{W}_{\beta}\) allow different scenarios of the cross-trait architecture of the independent effects on the phenotype (details described in \cref{section:model-design}).  

In the multi-variate case, the MLE of the trait covariances are \(P\times P\) trait-by-trait covariance matrices \tmatsub{C}{g} and \tmatsub{C}{n} for the genetic and noise components, respectively (Equation \ref{eq:lmm-mv}).

\begin{equation}
\mat{Y} =\mat{F}\mat{A}\mat{W}_{\alpha} +\mat{x}\mat{B}\mat{W}_{\beta} +\mat{g}+\mat{\psi},\text{ }
\mat{g}\sim \multinormal N P 0 {\matsub{C}{g} \otimes \matsub{R}{N}},\text{ }
\mat{\psi}\sim \multinormal N P 0 {\matsub{C}{n} \otimes \matsub{I}{N}}
\label{eq:lmm-mv}
\end{equation}

with
\begin{align*} 
& \text{the Kronecker product } \otimes \\
& \text{the phenotype matrix }\mat{Y} \inR N P ,\\
& \text{the matrix of $K$ covariates }\mat{F} \inR N K,\\
& \text{the effect of covariates } \mat{A} \inR K M,\\
& \text{the trait design matrix of the covariates }\matsub{W}{\alpha} \inR M P,\\
& \text{the genetype vector of the SNP being tested }\mat{x} \inR N 1\\
& \text{the effect size of the SNP } \mat{B} \inR 1 L \text{and}\\
& \text{the trait design matrix of the genotype }\matsub{W}{\beta} \inR L P,\\
\end{align*} 

In LMMs, both the residual noise and the genetic backgound are modeled as random effects. For the random genetic effect, a complex covariance structure can be modeled such that family structure and relatedness captured in the genotypes can be exploited to model background genetic correlations in phenotype\citep{Yu2006,Kang2008} (\cref{eq:lmm}). The random effects are assumed to be composed of a sample-by-sample and trait-by-trait covariance component. The genetic sample covariance can be obtained from the data itself, e.g. using a genetic relationship matrix (GRM) or identity by descent, whereas the trait covariance terms need to be estimated from the observed data. Since the introduction of LMM for multi-trait GWAS studies, LMMs have been extended to handle the large sample sizes obtained in particular in human studies, allowing for cohort sizes of \red{xxx}  individuals \citep{Zhou2014}. However nearly all current methods scale poorly in the number of traits ($P$) due to a bottle neck caused by estimating the trait covariance terms. 

\subsection{Model design}
\label{subsection:model-design}
In the most simple case, one can test if the genetic variant has an effect on any of the traits \(P\) (any effect test) i.e. the effect size of the fixed effect is unequal to zero for at least one trait : \(H_\text{A}: \mat{\beta} \ne \mat{0}_P\).  In this \(P\)-degrees of freedom test, the corresponding null hypthesis of no association is that the effect size of the fixed effect is equal to zero: \(H_0:\mat{\beta}  = \mat{0}_P\). In the common effect model, the variant has the same effect size across all traits (\(\mat{\beta}  = \mat{1}_P\beta)\) and is tested for significance in a one degree of freedom model versus the null hypothesis of no association (\(\mat{\beta}  = \mat{0}_P\)). A more complicated model allows to test for specific effects of the variant on a given trait \(p\). This can be tested with a one degree of freedom test where a model containing a common effect across all traits and a specific effect for trait \(p\) is compared against the common effect model.

For instance, in an 'common effect' setup where the genetic variant is assumed to have the same effect across all traits,  \tmat{B} is equal to \(1_{1xP}\) (\(L=1\)). Allowing different effects across all traits corresponds to  \( \mat{B} =  \matsub{I}{P} \) (\(L=P\)). In such a `any effect' setup, the multi-trait modelling simply serves to increase power for detecting genetic variants. 