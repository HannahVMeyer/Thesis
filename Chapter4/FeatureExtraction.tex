\section{Dimensionality reduction for feature extraction}
Apart from serving as a tool for visualisation, dimensionality reduction is often used for feature extraction. While visualisation is limited to one, two or three dimensions, for feature extraction one is interested in the intrinsic dimensionality of the data which can be of much higher dimension. Metrics, such as the one introduced in the previous section, can indicate which methods provide a trustworthy dimensionality reduction. However, they do not help with choosing the number of dimensions in the low-dimensional space. Here I propose a novel, simple stability criterion for the choice of dimension (\cref{subsection:stability-DimRed}) and show that features selected based on the stability criterion are able to capture underlying genetic structure (\cref{subsection:association-DimRed}).

\subsection{Stability of dimensionality reduction}
\label{subsection:stability-DimRed}
An assumption in dimensionality reduction for feature selection is that these techniques capture the variation or structure of the high-dimensional space in the low-dimensional components. In an ideal scenario, any technical or unwanted covariates have been accounted for \textit{a priori} (e.g. through regression) and the low-dimensional components will only capture the true biological structure in the data. While the dimensionality reduction techniques intrinsically learn structures based on the observed data, they should be robust against small changes in the data such as removing or adding a moderate number of samples. In the following, I will describe a method of finding robust low-dimensional representations and will call these representations stable.  As such, stability is a simple but effective way of ensuring reproducibility, but cannot be used to distinguish an appropriate from a less appropriate low-dimensional representation. In contrast, a dimensionality reduction that is \textit{not} stable is certainly not capable of producing reliable results.

In order to estimate the stability of the dimensionality reduction techniques and to investigate different parameters potentially influencing the stability, I used \textit{PhenotypeSimulator} (\cref{chapter:simulation}) to simulate datasets of \num{1000} phenotypes with different numbers of samples and phenotype components as described in \cref{section:phenotype-simulation}. The sample sizes ranged from \num{500} samples as observed in small cohort studies with dimensionality-reduced phenotypes \citep{Pausova2007} to \num{10000} \citep{Liu2012}. All phenotypes were simulated with genetic variant and infinitesimal effects and noise effects. A total of \num{50000} \glspl{snp} was simulated with allele frequencies of \numlist{0.1;0.2;0.4} chosen at equal probability. \num{20} \glspl{snp} were selected for the simulation of genetic variant effects with effect sizes drawn from \(\normal 0 1\) . The genetic kinship matrix was estimated based on all simulated \glspl{snp}. For each sample size, an additional phenotype set was simulated that also contained non-genetic covariate and correlated noise effects. The parameters for the simulation are summarised in \cref{tab:parametersSimulationDimRed}. For each simulation set-up, ten independent datasets were simulated and subsequent analyses applied to each dataset individually.

% Table generated by Excel2LaTeX from sheet 'SimulateDimRedNoise'
\begin{table}[h]
  \centering
  \caption[\textbf{Simulation parameters of phenotypes used for stability estimation. }]{\textbf{Simulation parameters of phenotypes used for stability estimation. }\(N\): number of samples, \(P\): number of traits; \(h_2\): total genetic variance, \(h_2^s\): variance of genetic variant effects, \(h_2^g\): variance of genetic random effects, \(1 - h_2\): total noise variance, \(\delta\): variance of non-genetic covariate effects, \(rho\): variance of correlated noise effects; pcorr: correlation of correlated noise effects, \(\theta\): proportion of shared genetic variant effects, \(\eta\):  proportion of shared genetic random effects,\(\gamma\): proportion of shared non-genetic covariate effects, \(\alpha\): proportion of shared noise random effects.}
    \begin{tabular}{lr}
    \toprule
    Parameter & Parameter values \\
    \midrule
    \(N\) & \num{500}, \num{1000}, \num{10000} \\
    \(P\) & \num{1000} \\
    \addlinespace[1.5ex]
    \(h_2\) & 0.4 \\
    \(h_2^s\) & 0.01 \\
    \(h_2^g\) & 0.99 \\
   \addlinespace[1.5ex]
    (1-\(h_2\)) & 0.6 \\
    (1-\(h_2\))\(\delta\) & 0.4, 0.4 \\
    (1-\(h_2\))(1-\(\delta\))\(\rho\) & 0.2, 0 \\
    (1-\(h_2\))(1-\(\delta\))(1-\(\rho\)) & 0.4, 0.6 \\
   \addlinespace[1.5ex]
    pcorr & 0.4 \\
    \(\theta\) & 0.8 \\
    \(\eta\) & 0.8 \\
    \(\gamma\) & 0.8 \\
    \(\alpha\) & 0.8 \\
    \bottomrule
    \end{tabular}%
  \label{tab:parametersSimulationDimRed}%
\end{table}%


To test the stability of dimensionality reduction techniques, I chose a cross-validation approach, where I randomly selected \num{80}\% of the simulated samples, applied a dimensional reduction technique and recorded the results. For each dataset, I repeated this step ten times. Subsequently, I did a pairwise comparison of the ten low-dimensional representations of the dataset, hence \num{45} comparisons. For each pairwise comparison, I selected the samples common to both datasets and computed the Spearman correlation of the components across these samples. I matched each of the components in the first dataset to the component in the second dataset with which it had maximum correlation. The matching algorithm started at the highest correlation and allowed for each component to be exactly matched once. In case of a tie, it was matched to the closest component in rank that had not been matched yet. After finding the pairs of highest correlation, I counted the number of components that passed a given threshold. Components that showed more than \num{90}\% correlation were considered stable. 

I applied the twelve dimensionality reduction methods described in \cref{section:DimReduction-methods} with the parameters summarised in \cref{tab:dimRed-R} to the different simulated datasets and determined the trustworthiness, continuity and stability of each method.  Instead of directly using the raw simulated data as input for the dimensionality reduction, I followed standard methods used the residuals from a linear regression of the simulated data with the known confounders (introduced as non-genetic covariate effects in the simulation).  For methods that required the specification of the dimensionality, I provided an initial estimate of \(ndim=100\).  These \num{100} dimensions will be the \num{100} components explaining most variance in the data for methods based on or including a pre-processing step that uses variance selection (\gls{pca}, \gls{drr}, \gls{tsne}, \gls{ica}, \gls{mds}, \gls{nmds} and Laplacian Eigenmaps). For \gls{peer}, which uses iterative model updates, selecting a dimensionality that is too high, will be compensated for by the weights associated with the components, which will effectively set the contribution of the non-informative components to  zero. In this way, an initial poor choice of too many dimensions will affect the final estimated components only minimally. In \gls{lle}, the provided dimension is only used as a maximum value and the estimation of any component is not affected by the estimation of subsequent components \citep{Roweis2000,Kayo2006}.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/TandCDimReductionSimulatedNoise.pdf}
	\caption[\textbf{Performance of dimensionality reduction techniques on simulated datasets.}]{\textbf{Performance of dimensionality reduction techniques on simulated datasets.} The trustworthiness and continuity (\cref{eq:trustworthiness} and \cref{eq:continuity}) of twelve dimensionality reduction methods on ten independent simulated datasets for each phenotype setup were computed.  \num{1000} phenotypes with non-genetic covariates and observational noise effects or non-genetic covariates, observational noise effects and correlated noise effects were simulated for datasets of \numlist{500;1000; 10000} samples. For each dataset, a ten-fold cross-validation of the dimensionality reduction and subsequent computation of trustworthiness and continuity was conducted. The results of ten evaluations on the ten independent datasets are summarised in the boxplots. A. Trustworthiness of the dimensionality reduction depending on the number of samples in the simulated dataset (noise background model: no correlated background). B. Trustworthiness depending on the background noise structure of the phenotypes (sample size: \num{10000}). C. Performance of the dimensionality reduction techniques in terms of trustworthiness and continuity (sample size:\num{1000}, noise background model: correlated background).}
	 	\label{fig:TaC-noise}
\end{figure}


\Cref{fig:TaC-noise} summarises the effects of sample size and background structure on the different dimensionality reduction methods. The effect is measured as the trustworthiness and continuity of the projection across the ten subsets of each dataset. For most methods, the sample size has only minor effects on the trustworthiness of the low-dimensional projection. Laplacian Eigenmaps are the exception to this observation, as the trustworthiness of the dimensionality-reduced datasets sharply increases with sample size (\cref{fig:TaC-noise}\subfig{A}). The effect of the background structure of the phenotype is shown in \cref{fig:TaC-noise}\subfig{B}. Most models perform marginally better on data without correlated background structure, while the trustworthiness of the representation found by Isomap and \gls{peer} is distinctly better on this data type. In contrast, \gls{ica} performs slightly better on datasets with correlated background structure. Two thirds of the models that yield trustworthy projections, also perform well in terms of continuity (\cref{fig:TaC-noise}\subfig{C}). \gls{peer} and \gls{ica} seem to be better at protecting original neighbourhoods (continuity), than they are at ensuring that the samples in low-dimensional space were in proximity in the original space (trustworthiness). The opposite trend can be observed for \gls{lle} and Laplacian Eigenmaps. \gls{kpca} performs worst overall and is only marginally better than randomly simulated neighbourhoods as a low-dimensional representation (\cref{section:Quantification-DimRed}).

The stability of the dimensionality reduction techniques dependent on the background model is displayed in \cref{fig:cor-noise}. For the majority of methods (\gls{drr}, \gls{mds}, Isomap, \gls{pca}, \gls{peer} and \gls{nmds}), the background structure of the dataset does not influence the stability of the components, with three components reliably recovered in the ten-fold cross-validation. DiffusionMaps and \gls{lle} detect more stable components for both data types with five and seven stable components in the data with correlated background and seven and five without correlated background, respectively. \gls{kpca} performs worse for both data types, while \gls{ica} has no components that pass the \num{0.9} correlation threshold for either of the data types. \gls{tsne} only finds stable components in the model with correlated background structure.  Results for the datasets with \num{500} and \num{10000} samples were consistent with these observations.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.8\textwidth]{Chapter4/Figures/CorrelationPassThr_Noise.pdf}
	\caption[\textbf{Stability of dimensionality reduction techniques for different background noise models.}]{\textbf{Stability of dimensionality reduction techniques for different background noise models. }The stability of twelve dimensionality reduction methods on the ten independently simulated datasets per setup were computed. \num{1000} phenotypes with non-genetic covariates and observational noise effects or non-genetic covariates, observational noise effects and correlated noise effects were simulated for the datasets with \numlist{1000} samples. For each dataset, a ten-fold cross-validation of the dimensionality reduction and subsequent evaluation of the stability was conducted. Components that passed the correlation threshold of \(cor=0.9\) were considered stable and the number of stable components per method is displayed. For \gls{ica}, no stable components were detected for either dataset, for \gls{tsne} the same was true for the dataset without correlated background structure.} 
	 	\label{fig:cor-noise}
\end{figure}

\subsection{Stable features enable discovery of genetic associations}
\label{subsection:association-DimRed}
In genetic association studies of high-dimensional phenotypes, features selected by dimensionality reduction methods serve as the response variable and one aims to find genetic components that are associated with this low-dimensional phenotype representation. Studies employing these techniques range from genotype association studies on features extracted from facial images \citep{Liu2012} and metabolic profiles \citep{Avery2011} to genome-wide pathway association studies of multiple correlated phenotypes \citep{Zhang2012}. These studies commonly test the association between \glspl{snp} and the top few components that explain most phenotypic variance. For instance,  the first eleven \glspl{pc} capturing more than \num{90}\% of variance of facial features were used as the phenotypes in the study by Liu and colleagues. Similarly, Avery and colleagues used the first eight \glspl{pc} extracted from the metabolic profiles based on \num{19} traits for the genotype to phenotype mapping analysis. Contrary to this common practice, \citet{Aschard2014} showed in simulations and in application to a datasets of coagulation traits that only testing the top \glspl{pc} can lead to a loss in power for detecting genetic associations. They demonstrated that combining signal across \glspl{pc} can increase power and that components explaining little phenotypic variance can be equally important as components explaining large variation. However, as seen in the previous section, phenotype components that reflect lower variance structures might reflect technical or biological noise and may not be recovered when subsampling the dataset. As such, the choice of dimensionality when using the extracted features for genotype to phenotype mapping comes down to a trade-off between gain in power and stability.

%The aforementioned studies have phenotypes ranging up to tens of traits. Far larger phenotype numbers are often observed for imaging-derived traits where each pixel/voxel is considered a trait \citep{Stein2010,xx} and the phenotypic trait number can increase from \numrange{1000}{100000} trait.

In order to test if the dimensionality reduction techniques employed so far can stably capture phenotypic components that yield enough power to serve as proxy phenotypes in association studies, I simulated a new set of phenotypes with genetic variant effects that affect different proportions of traits. I used the same strategy and parameter settings for the simulation of the noise effects as described for the phenotype simulation of the stability analysis, i.e. datasets with  non-genetic covariates and observational noise effects or non-genetic covariates, observational noise effects and correlated noise effects (\cref{tab:parametersSimulationDimRed}). For each of these datasets, I simulated different structures of genetic variant effects, by adding \num{20} \gls{snp} effects to a subset of traits. The percentage of affected traits ranged from \numrange{1}{100}, corresponding to ten and all \num{1000} simulated traits. Independent of the subset size, the proportion of variance of the genetic variant effects in relation to the total phenotypic variance was set to \(0.05\), corresponding to \(h^s_2=0.02\) for \(h_2=0.4\). The basis for the simulation of the genetic effects were the genotypes and kinship estimate of the simulated cohort with related individuals described in \cref{section:genotype-simulation}.  For each setup, i.e. each background noise model (with/without correlated background structure) and percentage of traits affected, I generated ten datasets and applied the twelve dimensionality reduction methods to each dataset. To determine the stability of the dimensionality reduction and decide which components to use for the genetic association study, I employed the cross-validation approach described in \cref{subsection:stability-DimRed}. 

For the majority of dimensionality reduction methods, the percentage of traits affected does not affect their stability in the dataset with correlated background structure (\cref{fig:cor-genetic}\subfig{A}). \gls{lle} and LaplacianEigenmaps do not follow this general observation and show some fluctuations in the stability, without showing an obvious trend.  \gls{ica} and \gls{tsne} on average do not find stable components for any number of traits affected. In the model without background structure (\cref{fig:cor-genetic}\subfig{B}), there is a general trend towards more stable components in the dataset when a larger subset of traits was affected by the genetics. DiffusionMaps and Laplacian Eigenmaps show the opposite behaviour, while there is no clear trend for \gls{tsne}. \gls{ica} can again not stably recover any components. For all methods, the median number of stable components across different proportions of traits influenced by genetics in the model without background structure is approximately the same as the number of components in the model with background structure. 

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/CorrelationPassThr_Genetic.pdf}
\caption[\textbf{Stability of dimensionality reduction techniques for different genetic variant and  observational noise models.}]{\textbf{Stability of dimensionality reduction techniques for different genetic variant and observational noise models. }A. Components from datasets with correlated background structure. B. Components from datasets without correlated background structure. The stability of twelve dimensionality reduction methods on ten independent simulations of ten datasets (two different noise background models, five subset sizes of traits affected by the genetic variant effect, \num{1000} phenotypes) were computed.  For each dataset, a ten-fold cross-validation of the dimensionality reduction with \num{80}\% of the \num{1000} samples and subsequent evaluation of the stability was conducted. Components with \(cor \ge 0.9\) were considered stable and the median number of stable components per method and dataset is displayed (points). The vertical lines indicate the \num{25}\% and \num{75}\% quantile for the ten independent simulations. } 
	 	\label{fig:cor-genetic}
\end{figure}

For every setup, stable components were selected and used as the response variables in a multivariate \gls{lmm} with an any effect trait design matrix (\cref{subsubsection:model-design}) for the \num{20} causal \glspl{snp} and the kinship matrix as the random genetic effect. The significance of the association was assessed by the permutation approach described in \cref{section:power-limmbo}, where the original p-values are compared to p-values from the same association model on permuted genotypes to obtain an empirical p-value. \Cref{fig:power-dimRed} shows the percentage of causal \glspl{snp} that could be detected with this approach (\(p_\text{empirical} < 0.01\)). \gls{ica} is not depicted as it was not possible to find stable components for any of the phenotype sets.  In general, the percentage of detected true \glspl{snp} is lower for components derived from phenotypes with correlated background structure (\cref{fig:power-dimRed}\subfig{A}) as compared to those from phenotypes without correlated structure (\cref{fig:power-dimRed}\subfig{B}). Similar to the observation for the stable number of components (\cref{fig:cor-genetic}), the percentage of detected \glspl{snp} does not vary much depending on the number of traits affected in the datasets with correlated background structure. For the phenotypes without correlated background structure, there is a trend towards detecting more \glspl{snp} for larger subsets of traits affected by the genetics. For both phenotype models, the \gls{pca}-based methods (\gls{drr}, \gls{mds}, \gls{pca} and \gls{peer}) and \gls{nmds} perform better in recovering the underlying genetics. These methods all perform best in finding components that allow for detecting causal \glspl{snp} in phenotypes where \num{40}\% of all traits where affected by the genetics, with up to \num{80}\% of \glspl{snp} detected on average. 
%
\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/power.pdf}
	\caption[\textbf{Genetic association of stable components from dimensionality reduction.}]{\textbf{Genetic association of stable components from dimensionality reduction. } A. Detected \glspl{snp} from datasets with correlated background structure. B.  Detected \glspl{snp} from datasets without correlated background structure. The stable components for each dataset were used as the response variables in a multivariate \gls{lmm} with an any effect trait design matrix for the \num{20} causal \glspl{snp} and the kinship matrix as the random genetic effect. Vertical lines indicate the \num{25}\% and \num{75}\% quantile, points represent the median for the ten independent simulations. } 
	 	\label{fig:power-dimRed}
\end{figure}


The power to detect \glspl{snp} in the standard genotype-phenotype mapping approach depends, among other factors such as sample size and allele frequency, on the effect sizes of the \gls{snp} \citep{Cohen1992,Halsey2015,Astle2016}.  For phenotypes derived via dimensionality reduction, the effect size of the \gls{snp} has an additional influence on the outcome of the association.  While the effect size of the \gls{snp} is linked to power as in any genotype-phenotype mapping, its influence is likely to also occur before the mapping, namely in finding stable components that reflect this genetic structure. 

To test if finding low-dimensional components that capture the underlying genetics depends on the effect size of the causal \glspl{snp}, I computed the mean absolute value of effect sizes from the causal \glspl{snp} for all simulated datasets. I then classified these \glspl{snp} into two categories, based on passing the FDR threshold of \(p_\text{empirical} < 0.01\). \glspl{snp} with empirical p-values below that threshold are considered \textquote{detected}, the remainder are \textquote{not-detected}. \Cref{fig:effectsizes-dimRed} depicts the effect sizes of these \gls{snp} categories dependent on the dimensionality reduction technique that was used for deriving the phenotypes, summarised across all proportions of traits affected by the genetic variant effects. \gls{ica} and \gls{kpca} are not depicted as they either did not detect stable components or their stable components did not detect associations. On average, the effect size of the detected \glspl{snp} are larger than the ones for \glspl{snp} that are not detected. The results for the linear methods (\gls{mds}, \gls{peer}, \gls{pca}) and \gls{nmds} are mostly identical, with median effect sizes for detected \glspl{snp} slightly higher in the model with correlated background (\cref{fig:effectsizes-dimRed}\subfig{A}) than without (\cref{fig:effectsizes-dimRed}\subfig{B}). \gls{drr} follows the same trend as does \gls{lle}, albeit on marginally higher effect size levels. DiffusionMaps, Laplacian Eigenmaps, Isomap and \gls{tsne} require higher effect sizes to detect \glspl{snp} in the model without correlated background structure. The spread and number of outliers of effect sizes for undetected causal \glspl{snp} is smallest for \gls{drr}, \gls{mds}, \gls{peer}, \gls{pca} and \gls{nmds} for both noise background models. For the background model with correlated structure, the spread of effect sizes for DiffusionMaps is equally low with a median of \num{0.2}. For the other methods, large numbers of outliers for \glspl{snp} with high effect sizes that could not be detected are observed, i.e. \glspl{snp} with high effect sizes that were not detected.
%
\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/effectsizes.pdf}
	\caption[\textbf{Effect size distribution of discovered SNPs.}]{\textbf{Effect size distribution of discovered SNPs. } A. Power from datasets with correlated background structure. B. Power from datasets without correlated background structure. The mean of the simulated effect sizes per \gls{snp} across all traits was computed. \glspl{snp} were classified into \textquote{detected} and \textquote{not-detected} based on the threshold \(p_\text{empirical} < 0.01\). The plot shows the dependence of detecting causal \glspl{snp} on their effect size for different background models and dimensionality reduction techniques across all proportions of traits affected by the \glspl{snp}.} 
	 	\label{fig:effectsizes-dimRed}
\end{figure}
%
\section{Dimensionality reduction is a powerful tool for genetic association studies}
In this chapter, I reviewed dimensionality reduction methods with different properties and underlying mathematical concepts. I analysed their performance in terms of trustworthiness and continuity and introduced a new measure, stability, to asses the low dimensional phenotype representations they generate. Finally, I investigated if using low-dimensional representations of the original phenotypes are capable of recovering the underlying genetic structure in simulations.

I was able show on datasets with known structure (\textit{Iris} and roll dataset) that the trustworthiness and continuity criteria agree with the visual assessment of the methods' performance. Based on these results, I used the trustworthiness and continuity criteria to evaluate the effect of sample size and phenotype structure on the performance of the different methods. For the majority of methods analysed in this thesis, the sample size has only minor effects on the performance. In general, most models perform marginally better on data without correlated background structure. Trustworthiness and continuity are helpful in determining the correspondence of the high- and low-dimensional space. The stability criterion that I defined in this chapter evaluates a different aspect of the dimensionality reduction. It measures the number of components that can be reliably recovered in cross-validation and thus helps to determine the stable dimensions of the low-dimensional space. Applied to the two different data types, with and without background structure, it shows that background structure alone does not influence the number of stable components much. A stronger effect on the number of stably recovered components is observed when varying the proportions of traits influenced by the genetic variant effects. This seems intuitive since \gls{snp} effects are mathematically equivalent to any other type of fixed effect confounders that are present in the data. An increase in the proportion of traits affected generally leads to an increase in components recovered. This increase is maximal for about \numrange{40}{80}\% of traits affected. This trend is reflected in the number of causal \glspl{snp} that can be detected when using the stable components as phenotypes in a genetic association model. The higher number of stable components at \numrange{40}{80}\% of traits affected captures more of the underlying genetics. 

In the analyses of stability and power to detect genetic associations, the linear and \gls{pca}-derived methods seemed to outperform the other methods. In particular, \gls{kpca}, \gls{ica} and \gls{tsne} yielded the least promising results: \gls{ica} did not recover any stable components, while the number was very low for \gls{kpca} and \gls{tsne} did only find stable components in the model of correlated background structure. In the association analyses, these components were either not associated at all (\gls{kpca}) or only for \glspl{snp} with large effect sizes (\gls{tsne}). However, there is a point of caution in these conclusions. Foremost, the performance of all these methods is intrinsically linked to the underlying data structure. Thus, in general, the different mathematical models of the dimensionality reduction methods will make some models more suitable for the analysis of a given dataset than others. In this simulation study, the high-dimensional datasets for stability and genetic association analyses are more similar to the \textit{Iris} data than to the roll dataset. As such, it is encouraging that the chosen evaluation criteria trustworthiness and continuity show similar results for suitability of the methods, i.e. linear methods seem to perform better on linear data than the non-linear methods. In addition, the non-linear methods all require the specification of model parameters for which I chose the default settings. Improved results might be observed when different parameter settings are evaluated for the different methods. To extend and improve this study, high-dimensional datasets more reflective of the non-linear structure of the roll dataset could be simulated and the non-linear dimensionality reduction methods evaluated on a range of parameter settings. 

This simulation study has shown that dimensionality reduction methods are a valid intermediate step in genotype to phenotype mapping of high-dimensional datasets. Although methods like \gls{limmbo} (\cref{chapter:limmbo}) enable association studies with large numbers of phenotypes, there is always a trade-off between exploiting correlated structure in the phenotypes and the joint mapping cost in form of degrees of freedom when evaluating the test statistic. Employing dimensionality reduction techniques to find the correlated background structures in the phenotypes while simultaneously reducing the degrees of freedom offers huge potential for the multivariate analysis of these phenotypic traits. For applications on real data, one should carefully evaluate different dimensionality reduction methods as the choice strongly depends on the data and investigate parameter settings to find components that best reflect the original data. The introduced stability criteria is particularly useful in genetic association studies as dimensionality reductions that are not stable are guaranteed not to produce reliable results.



