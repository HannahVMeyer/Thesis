\section{Dimensionality reduction for feature extraction}
Apart from serving as a tool for visualisation, dimensionality reduction is often used for feature extraction. While visualisation is limited to \num{2} or three dimensions, for feature extraction one is intrested in the intrinsice dimensionality of the data which can be of much higher dimension and there is no simple way to comprehensively visualise the results. Metrics, such as the one introduced in the previous section, can indicate which methods provide a trustworthy dimensionality reduction. However, they do not help with chosing the number of dimensions in the low-dimensional space. Here I propose a novel, simple stability criterion for the choice of dimension (\cref{subsection:stability-DimRed}) and show that features selected based on the stability criterion are able to capture underlying genetic structure (\cref{subsection:association-DimRed}).

\subsection{Stability of dimensionality reduction}
\label{subsection:stability-DimRed}
The assumption in dimensionality reduction for feature selection is that these techniques capture the variation or structure of the high-dimensional space in the low-dimensional components. In an ideal scenario, any technical or unwanted covariates have been accounted for \textit{a priori} (e.g. through regression) and the low-dimensional components will only capture the true biological structure in the data. While the dimensionality reduction techniques intrinsicly learn structures based on the observed data, small changes in the data such as removing or adding a moderate number of samples which lead to subtle changes in the overall variance of the data, should not influence the stability of the dimensionality reduction. The choice of dimensionality based on stability tries to protect from chosing dimensions that capture this variation. As such, stability is a simple but effective way of ensuring reproducibility, but cannot be used to distinguish an appropriate from a less appropriate low-dimensional representation. In contrast however, a dimensionality reduction that is not stable is certainly not capable of producing reliable results.

In order to find a way of estimating the stability of the dimensionality reduction techniques and to investigate different parameters potentially influencing the stability, I used PhenotypeSimulator (\cref{chapter:simulation}) to simulate datasets of \num{1000} phenotypes with different numbers of samples and phenotype components as described in \cref{section:phenotype-simulation}. The sample sizes ranged from \num{500} samples as observed in small cohort studies with dimensionality-reduced phenotypes \citep{Pausova2007} to \num{10000} \citep{Liu2012}. All phenotypes were simulated with fixed and random genetic and noise effects. A total of \num{50000} SNPs was simulated with allele frequencies of \numlist{0.1;0.2;0.4} chosen at equal probability. \num{20} SNPs were selected for the simulation of fixed genetic effects with effect sizes drawn from \(\normal 0 1\) . The genetic kinship matrix was estimated based on all simulated SNPs. For each sample size, an additional phenotype set was simulated that also contained fixed and correlated noise effects. The parameters for the simulation are summarised in \cref{tab:parametersSimulationDimRed}. For each simulation set-up, ten independent datasets were simulated and subsequent analyses applied to each dataset individually.

% Table generated by Excel2LaTeX from sheet 'SimulateDimRedNoise'
\begin{table}[h]
  \centering
  \caption[\textbf{Simulation parameters of phenotypes used for stability estimation. }]{\textbf{Simulation parameters of phenotypes used for stability estimation. }\(N\): number of samples, \(P\): number of traits; \(h_2\): total genetic variance, \(h_2^s\): variance of genetic  fixed effects, \(h_2^g\): variance of genetic random effects, \(1 - h_2\): total noise variance, \(\delta\): variance of noise fixed effects, \(rho\): variance of correlated noise effects; pcorr: correlation of correlated noise effects, \(\theta\): proportion of shared genetic fixed effects, \(\eta\):  proportion of shared genetic random effects,\(\gamma\): proportion of shared noise fixed effects, \(\alpha\): proportion of shared noise random effects.}
    \begin{tabular}{lr}
    \toprule
    Parameter & Parameter values \\
    \midrule
    \(N\) & \num{500},\num{1000}, \num{10000} \\
    \(P\) & \num{1000} \\
    \addlinespace[1.5ex]
    \(h_2\) & 0.4 \\
    \(h_2^s\) & 0.025 \\
    \(h_2^g\) & 0.375 \\
   \addlinespace[1.5ex]
    (1-\(h_2\)) & 0.6 \\
    (1-\(h_2\))\(\delta\) & 0.24,0.24 \\
    (1-\(h_2\))(1-\(\delta\))\(\rho\) & 0.12,0 \\
    (1-\(h_2\))(1-\(\delta\))(1-\(\rho\)) & 0.24, 0.36 \\
   \addlinespace[1.5ex]
    pcorr & 0.4 \\
    \(\theta\) & 0.8 \\
    \(\eta\) & 0.8 \\
    \(\gamma\) & 0.8 \\
    \(\alpha\) & 0.8 \\
    \bottomrule
    \end{tabular}%
  \label{tab:parametersSimulationDimRed}%
\end{table}%


To test the stability of dimensionality reduction techniques, I chose a cross-validation approach, where I randomly selected \num{80}\% of the simulated samples, applied a dimensional reduction technique and recorded the results. For each dataset, I repeated this step ten times. Subsequently, I did a pairwise comparison of the ten low-dimensional representations of the dataset, hence \num{45} comparisons. For each pairwise comparison, I selected the samples common to both datasets and computed the Spearman correlation of the components across these samples. I matched each of the components in the first dataset to the component in the second dataset with which it had maximum correlation. The matching algorithm started at the highest correlation and allowed for each component to be exactly matched once. In case of a tie, it was matched to the closest component in rank that had not been matched yet. After finding the pairs of highest correlation, I counted the number of components that passed a given threshold. Components that showed more than \num{90}\% correlation were considered stable. 

I applied the twelve dimensionality reduction methods described in \cref{section:DimReduction-methods} with the parameters summarised in \cref{tab:dimRed-R} to the different simulated datasets and determined the trustworthiness, continuity and stability of each method.  Instead of directly using the raw simulated data as input for the dimensionality reduction, I followed standard methods used the residuals from a linear regression of the simulated data with the known confounders (introduced as fixed noise effects in the simulation).  For methods that required the specification of the dimensionality, I provided an initial estimate of \(ndim=100\).  These \num{100} dimensions will be the \num{100} components explaining most variance in the data for methods based on or including a pre-processing step that uses variance selection (PCA, DRR, tSNE, ICA, MDS, nMDS and Laplacian Eigenmaps). For PEER, which uses iterative model updates, selecting a dimensionality that is too high, will be compensated for by the weights associated with the components, which will effectivly set the contribution of the non-informative components to  zero. In this way, an initial poor choice of too many dimensions will affect the final estimated components only minimally. In LLE, the provided dimension is only used as a maximum value and the estimation of any component is not affected by the estimation of subsequent components \citep{Roweis2000,Kayo2006}.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/TandCDimReductionSimulatedNoise.pdf}
	\caption[\textbf{Performance of dimensionality reduction techniques on simulated datasets.}]{\textbf{Performance of dimensionality reduction techniques on simulated datasets.} The trustworthiness and continuity (\cref{eq:trustworthiness} and \cref{eq:continuity}) of twelve dimensionality reduction methods on ten independent simulated datasets for each phenotype set-up were computed.  \num{1000} phenotypes with fixed and random noise or fixed, random and correlated noise effects were simulated for datasets of \numlist{500;1000; 10000} samples. For each dataset, a ten-fold crossvalidation of the dimensionality reduction and subsequent computation of trustworthiness and continuity was conducted. The results of ten evaluations on the ten independent datasets are summarized in the boxplots. A. Trustworthiness of the dimensionality reduction depending on the number of samples in the simulated dataset (noise background model: no correlated background). B. Trustworthiness depending on the background noise structure of the phenotypes (sample size: \num{10000}). C. Performance of the dimensionality reduction techniques in terms of trustworthiness and continuity (sample size:\num{1000}, noise background model: correlated background).}
	 	\label{fig:TaC-noise}
\end{figure}


\Cref{fig:TaC-noise} summarises the effects of sample size and background structure on the different dimensionality reduction methods. The effect is meassurd as the trustworthiness and continuity of the projection across the ten subsets of each dataset. For most methods, the sample size has only minor effects on the trustworthiness of the low-dimensional projection. Laplacian Eigenmaps are the exception to this observation, as the trustworthiness of the dimensionality-reduced datasets sharply increases with sample size (\cref{fig:TaC-noise}\subfig{A}). The effect of the background structure of the phenotype is shown in \cref{fig:TaC-noise}\subfig{B}. Most models perform marginally better on data without correlated background structure, while the trustworthiness of the representaton found by Isomap and PEER is distinctly better on this data type. In contrast, ICA performs slightly better on datasets with correlated background structure. Two thirds of the models that yield trustworthy projections, also perform well in terms of continuity (\cref{fig:TaC-noise}\subfig{C}). PEER and ICA seem to be better in protecting original neighbourhoods (continuity), than they are in ensuring that the samples in low-dimensional space where originally in proximity (trustworthiness). The opposite trend can be observed for LLE and Laplacian Eigenmaps. kPCA performs worst overall and is only marginally better than randomly simulated neighbourhoods as a low-dimensional representation (\cref{section:Quantification-DimRed}).

The stability of the dimensionality reduction techniques dependent on the background model is displayed in \cref{fig:cor-noise}. For the majority of methods (DRR, MDS, Isomap, PCA, PEER and nMDS), the background structure of the dataset does not influence the stability of the components, with three components reliably recovered in the ten-fold cross-validation. DiffusionMaps and LLE detect more stable components for both data types with five and seven stable components in the data with correlated background and seven and five without correlated background, respectivly. kPCA performs worse for both data types, while ICA has no components that pass the \num{0.9} correlation threshold for either of the data types. tSNE only finds stable components in the model with correlated background structure.  Results for the datasets with \num{500} and \num{10000} samples were consistent with these observations.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.8\textwidth]{Chapter4/Figures/CorrelationPassThr_Noise.pdf}
	\caption[\textbf{Stability of dimensionality reduction techniques for different background noise models.}]{\textbf{Stability of dimensionality reduction techniques for different background noise models. }The stability of twelve dimensionality reduction methods on the ten independently simulated datasets per set-up were computed. \num{1000} phenotypes with fixed and random noise or fixed, random and correlated noise effects were simulated for the datasets with \numlist{1000} samples. For each dataset, a ten-fold crossvalidation of the dimensionality reduction and subsequent evaluation of the stability was conducted. Components that passed the correlation threshold of \(cor=0.9\) were considered stable and the number of stable components per method is displayed. For ICA, no stable components were detected for either dataset, for tSNE the same was true for the dataset without correlated background structure.} 
	 	\label{fig:cor-noise}
\end{figure}

\subsection{Stable features allow for discovery of genetic associations}
\label{subsection:association-DimRed}
In genetic association studies of high-dimensional phenotypes, features selected by dimensionality reduction methods serve as the response variable and one aims to find genetic components that are significantly associated with this low-dimensional phenotype representation. Studies employing these techniques range from genotype assocation studies on features extracted from facial images \citep{Liu2012} and metabolic profiles \citep{Avery2011} to genome-wide pathway association studies of multiple correlated phenotypes \citep{Zhang2012}. These studies commonly test the association between SNPs and the top few components that explain most phenotypic variance. For instance,  the first eleven PCs capturing more than \num{90}\% of variance of facial features were used as the phenotypes in the study by Liu and colleagues. Similarily, Avery and colleagues used the first eight PCs extracted from the metabolic profiles based on \num{19} traits for the genotype to phenotype mapping analysis. Contrary to this common practice, Aschard and colleagues showed in simulations and in application to a datasets of coagulation traits that only testing the top PCs can lead to a loss in power for detecting genetic associations. They demonstrated that combining signal across PCs can increase power and that components explaining little phenotypic variance can be equally important as components explaining large variation \citep{Aschard2104}. However, as seen in the previous section, phenotype components that reflect lower variance structures might reflect technical or biological noise and cannot be recovered when subsampling the dataset. As such, the choice of dimensionality when using the extracted features for genotype to phenotype mapping comes down to a trade-off between power gain and stability.

%The aforementioned studies have phenotypes ranging up to tens of traits. Far larger phenotype numbers are often observed for imaging-derived traits where each pixel/voxel is considered a trait \citep{Stein2010,xx} and the phenotypic trait number can increase from \numrange{1000}{100000} trait.

In order to test if the dimensionality reduction techniques employed so far can stably capture phenotypic components that yield enough power to serve as proxy phenotypes in association studies, I simulated a new set of phenotypes with genetic fixed effects that affect different proportions of traits. I used the same strategy and parameter settings for the simulation of the noise effects as described for the phenotype simulation of the stability analysis, i.e. datasets with fixed and random as well as datasets with fixed, correlated and random noise effects (\cref{tab:parametersSimulationDimRed}). For each of these datasets, I simulated different structures of genetic fixed effects, by adding \num{20} SNP effects to a subset of traits.  The percentage of affected traits ranged from \numrange{1}{100}, corresponding to ten and all \num{1000} simulated traits. Independent of the subset size, the proportion of variance of the fixed genetic effects in relation to the total phenotypic variance was set to \(0.05\), corresponding to \(h^s_2=0.02\) for \(h_2=0.4\). The basis for the simulation of the genetic effects were the gentoypes and kinship estimate of the simulated cohort with related individuals described in \cref{section:genotype-simulation}.  For each set-up, i.e. each background noise model (with/without correlated background structure) and percentage of traits affected, I generated ten datasets and applied the twelve dimensionality reduction methods to each dataset. To determine the stability of the dimensionality reduction and decide which components to use for the genetic association study, I employed the cross-validation approach described in \cref{subsection:stability-DimRed}. 

For the majority of dimensionality reduction methods, the percentage of traits affected does not affect their stability in the dataset with correlated background structure (\cref{fig:cor-genetic}\subfig{A}). LLE and LaplacianEigenmaps do not follow this general observation and show some fluctuations in the stability, however without showing an obvious trend.  ICA and tSNE on average do not find stable components for any number of traits affected. In the model without background structure (\cref{fig:cor-genetic}\subfig{B}), there is a general trend towards more stable components in the dataset when a larger subset of traits was affected by the genetics. DiffusionMaps and Laplacian Eigenmaps show the opposite behaviour, while there is no clear trend for tSNE. ICA can again not stably recover any components. For all methods, the median number of stable components across different proportions of traits influenced by genetics in the model without background structure is approximately the same as the number of components in the model with background structure. Interestingly, for all methods (except for LLE) with the upward trajectory in number of stable features, the number of stable components when all traits are affected by genetics is only as high or lower than the number observed when \num{80}\% of the traits are affected. 

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/CorrelationPassThr_Genetic.pdf}
\caption[\textbf{Stability of dimensionality reduction techniques for different fixed genetic and background noise models.}]{\textbf{Stability of dimensionality reduction techniques for different fixed genetic and background noise models. }A. Components from datasets with correlated background structure. B. Components from datasets without correlated background structure. The stability of twelve dimensionality reduction methods on ten independent simulations of ten datasets (two different noise background models, five subset sizes of traits affected by the fixed genetic effect, \num{1000} phenotypes) were computed.  For each dataset, a ten-fold crossvalidation of the dimensionality reduction with \num{80}\% of the \num{1000} samples and subsequent evaluation of the stability was conducted. Components with \(cor \ge 0.9\) were considered stable and the median number of stable components per method and dataset is displayed (points). The vertical lines indicate the \num{25}\% and \num{75}\% quantile for the ten independent simulations. } 
	 	\label{fig:cor-genetic}
\end{figure}

For every set-up, stable components were selected and used as the response variables in a multi-variate LMM with an any effect trait design matrix (\cref{section:model-design}) for the \num{20} causal SNPs and the kinship matrix as the random genetic effect. The significance of the association was assessed by the permutation approach described in \cref{section:power-limmbo}, where the original p-values are compared to p-values from the same assocation model on permutated genotypes to obtain an empirical p-value. \Cref{fig:power-dimRed} shows the percentage of causal SNPs that could be detected with this approach (\(p_\text{empirical} < 0.01\)). ICA is not depicted as it was not possible to find stable components for any of the phenotpe sets.  In general, the percentage of detected true SNPs is lower for components derived from phenotypes with correlated background structure (\cref{fig:power-dimRed}\subfig{A}) as compared to those from phenotypes without correlated structure (\cref{fig:power-dimRed}\subfig{B}). Similar to the observation for the stable number of components (\cref{fig:cor-genetic}), the percentage of detected SNPs does not vary much dependent on the number of traits affected in the datasets with correlated background structure. For the phenotypes without correlated background structure, there is a trend towards detecting more SNPs for larger subsets of traits affected by the genetics. For both phenotype models, the PCA-based methods (DRR, MDS, PCA and PEER) and nMDS perform better in recovering the underlying genetics. These methods all perform best in finding components that allow for detecting causal SNPs in phenotypes where \num{40}\% of all traits where affected by the genetics, with up to \num{80}\% of SNPs detected on average. 

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/power.pdf}
	\caption[\textbf{Genetic association of stable components from dimensionality reduction.}]{\textbf{Genetic association of stable components from dimensionality reduction. } A. Dectected SNPs from datasets with correlated background structure. B.  Dectected SNPs from datasets without correlated background structure. The stable components for each dataset were used as the response variables in a multi-variate LMM with an any effect trait design matrix for the \num{20} causal SNPs and the kinship matrix as the random genetic effect. Vertical lines indicate the \num{25}\% and \num{75}\% quantile, points the median for the ten independent simulations. } 
	 	\label{fig:power-dimRed}
\end{figure}

The power to detect SNPs in the standard genotype-phenotype mapping approach depends -amongst other factors such as sample size and allele frequency- on the effect sizes of the SNP \citep{Cohen1992,Halsey2015,Astle2016}.  For phenotypes derived via dimensionality reduction, the effect size of the SNP has an additional influence on the outcome of the association.  While the effect size of the SNP is linked to power as in any genotype-phenotype mapping, its influence is likely to occur before the mapping, namely in finding stable components that reflect this genetic structure. 

To analyse if finding low-dimensional components that capture the underlying genetics depends on the effect size of the causal SNPs, I computed the mean absolute value of effect sizes from the causal SNPs for all simulated datasets. I then classified these SNPs into \num{2} categories, based on passing the FDR threshold of \(p_\text{empirical} < 0.01\). SNPs with empirical p-values below that threshold are considered `detected', the remainder are `not-detected'. \Cref{fig:effectsizes-dimRed} depicts the effect sizes of these SNP categories dependent on the dimensionality reduction technique that was used for deriving the phenotypes, summarised across all proportions of traits affected by the fixed genetic effects. ICA and kPCA are not depicted as the either did not detect stable components or their stable components did not yield significant associations. On average, the effect size of the detected SNPs are larger than the ones for SNPs that are not detected. The results for the linear methods (MDS, PEER, PCA) and nMDS are mostly identical, with median effect sizes for detected SNPs slightly higher in the model with correlated background (\cref{fig:effectsizes-dimRed}\subfig{A}) than without (\cref{fig:effectsizes-dimRed}\subfig{B}). DRR follows the same trend as does LLE, albeit on marginally higher effect size levels. DiffusionMaps, Laplacian Eigenmaps, Isomap and tSNE require higher effect sizes to detect SNPs in the model without correlated background structure. The spread and number of outliers of effect sizes for undetected causal SNPs is smallest for DRR, MDS, PEER, PCA and nMDS for both noise background models. For the background model with correlated structure, the spread of effect sizes for Diffusionmaps is equally low with medians of \num{0.2}. For the other methods, large numbers of outliers for SNPs with high effect sizes that could not be detected are observed, i.e. SNPs with high effect sizes that were not detected.

 


\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=\textwidth]{Chapter4/Figures/effectsizes.pdf}
	\caption[\textbf{Effect size distribution of discovered SNPs.}]{\textbf{Effect size distribution of discovered SNPs. } A. Power from datasets with correlated background structure. B. Power from datasets without correlated background structure. The mean of the simulated effect sizes per SNP accross all traits was computed. SNPs were classified into `detected' and `not-detected` based on the threshold \(p_\text{empirical} < 0.01\). The plot shows the dependence of detecting causal SNPs on their effect size for different background models and dimensionality reduction techniques across all proportions of traits affected by the SNPs.} 
	 	\label{fig:effectsizes-dimRed}
\end{figure}

\section{Dimensionality reduction is a powerful tool for genetic association studies}
In this chapter, I reviewed dimensionality reduction methods with different properties and underlying mathematical concepts. I analysed their performance in terms of trustworthiness and continuity and introduced a new measure, stability, to asses the low dimensional phenotype representations they generate. Finally, I investigated if using low-dimensional representations of the original phenotypes are capable of recovering the underlying genetic structure. 

I could show on datasets with known structure (iris and roll dataset) that the trustworthiness and continuity criteria agree with the visual assessment of the methods' performance. Based on these results, I used the trustworthiness and continuity criteria to evaluate the effect of sample size and phenotype structure on the performance of the different methods. For the majority of methods analysed in this thesis, the sample size has only minor effects on the performance. In general, most models perform marginally better on data without correlated background structure. Trustworthiness and continuity are helpful in determining the correspondence of the high- and low-dimensional space. The stability criterion that I defined in this chapter evaluates a different aspect of the dimensionality reduction. It measures the number of components that can be reliably recovered in cross-validation and thus helps to determine the stable dimension of the low-dimensional space. Applied to the two different data types, with and without background structure, it shows that background structure alone does not influence the number of stable components much. A stronger effect on the number of stably recovered components is observed when varying the porportions of traits influenced by the fixed genetic effects. This seems intuitive since SNP effects are mathematically the same as any other type of fixed effect confounders that are present in the data. An increase in the proportion of traits affected generally leads to an increase in components recovered. The increase is maximal for about \numrange{40}{80}\% of traits affected in methods that follow this trajectory. This trend is reflected in the number of causal SNPs that can be detected when using the stable components as phenotypes in a genetic association model. The higher number of stable components at \numrange{40}{80}\% of traits affected captures more of the underlying genetics. 

In the analyses of stability and power to detect genetic associations, the linear and PCA-derived methods seemed to outperform the other methods. In particular, kPCA, ICA and tSNE yielded the least promising results: ICA did not recover any stable components, while the number was very low for kPCA and tSNE did only find stable components in the model of correlated background structure. In the association analyses, these components were either not associated at all (kPCA) or only for SNPs with large effect sizes (tSNE). However, there is a point of caution in these conclusions. Foremost, the performance of all these methods is intrinsically linked to the underlying data structure. The high-dimensional simulated datasets for stability and genetic association analyses are more similar to the iris data than to the roll dataset. As such, it is encouraging that similar results for suitability of the methods were observed, i.e. linear methods seem to perform better on linear data than the non-linear methods. In addition, the non-linear methods all require the specification of model parameters for which I chose the default settings. Improved results might be observed when different parameter settings are evaluated for the different methods. To extend and improve this study, high-dimensional datasets more reflective of the non-linear structure of the roll dataset could be simulated and the non-linear dimensionality reduction methods evaluated on a range of parameter settings. 

This simulation study has shown that dimensionality reduction methods are a valid intermediate step in genotype to phenotype mapping of high-dimensional datasets. Although methods like LiMMBo (\cref{chapter:limmbo}) allow for  association studies with large numbers of phenotypes, there is always a trade-off between exploiting correlated structure in the phenotypes and the joint mapping cost in form of degrees of freedom when converting the test statistic. Employing dimensionality reduction techniques to find the correlated background structures in the phenotypes while simultaneously reducing the degrees of freedom offers huge potential for the multi-variate analysis of these phenotypic traits. For applications on real data, one should carefully evaluate different dimensionality reduction methods as the choice strongly depends on the data and investigate parameter settings to find components that best reflect the original data. By applying the stability criterion, results should be robust to fluctuations in sample composition and extending sample sizes should yield similar components that can be used for genetic association. 


