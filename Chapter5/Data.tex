\section{Data}
\subsection{Genotypes}
\label{subsection:genotypes}
\paragraph{Quality Control.} Genotyping and genotype calling were carried out at the Genotyping and Microarray facility at the Wellcome Trust Sanger Institute, UK and Duke-NUS Medical School, Singapore. Genotypes were assessed in five batches using Illumina HumanOmniExpress- 12v1-1 (Sanger, two batches), Illumina HumanOmniEx\-press-24v1-0 (Duke-NUS, two batches) and Illumina HumanOmniExpress- 24v1-1 chips (Duke-NUS). SNPs were called via the GenCall software for clustering, calling and scoring of genotypes \citep{Teo2007}. For batches run on the same platform, genotype signals were combined and called in a single analysis, leading to three independent genotype batches: Sanger12 (\num{1344} samples), Duke-NUS12 (\num{284} samples), Duke-NUS3 (\num{96} samples). I carried out the quality control (QC) on the raw genotype calls, the phasing and the imputation, at a per-batch level. The final QC of the imputed data was conducted across all batches and only SNPs passing the control in every batch were used in subsequent analyses. 

Prior to QC, I matched the rsID descriptions (chromosome, chromosomal positions and allele order) of the three batches to the reference set I would use for imputation, a combined UK10K \citep{UK10KConsortium2015} and \num{1000} Genomes \citep{1000Genomes2015} reference panel. For rsIDs not included in the reference panel I retrieved location and allele order from the ensembl human variation annotation (GRCh37p13, 15.04.2016). rsIDs that matched to neither reference were removed from further analyses (\num{4681} across all chips). In order to avoid batch effects in SNP calling simply based on the probe sequences, I confirmed that probes targeting the same SNP on different chip versions had the same sequence. As this was the case, no SNPs were removed at this stage. 
I followed an adapted quality control protocol from \citet{Anderson2010} to asses the quality of the genotyping on a per-individual and per-marker level. Unless stated otherwise, the PLINK software (version 1.9) \citep{Purcell2007, Chang2015} was used for all QC analyses. In summary, the per-individual QC included the identification of individuals with discordant sex information, missing SNP rates (more than 3\% of SNPs not called) and heterozygosity rate outliers (three standard deviations outside of the mean heterozygosity rate). Population substructures arising due to different ethnical origins of samples were examined by comparing the sample genotypes to genotypes from the HapMap Phase III study \citep{HapMap2005} for four ethnic populations (with subpopulations, \cref{fig:kinshipQC} in the appendix). Samples that clustered with HapMap III individuals of Caucasian ancestry were kept for further analyses. The per-marker QC included filtering of SNPs with missing call rate in more than \num{1}\% of the samples and SNPs which significantly deviate from Hardy-Weinberg equilibrium (HWE, \(p < 0.001\)). After removing samples and SNPs that failed QC, I confimed that any pattern of missing genotype information was not batch-specific. To analyse these patterns, I treated each pair-wise combination of batches as a case-control set-up and computed the differential missingness of SNPs common to all batches. None of the \num{631877} common SNPs had to be removed due to significant differential missingness (\(p < 10^{-5}\)). Table~\ref{tab:genoOverview} shows an overview of sample and SNP numbers before and after the QC described above. The QC plots for each step can be found in \cref{fig:sampleQC,fig:SNPQC,fig:kinshipQC} in the appendix. 
\\
% Table generated by Excel2LaTeX from sheet 'GenotypesSummary'
\begin{table}[htbp]
  \centering
  \caption[\textbf{Sample and SNP numbers before and after the QC. }]{\textbf{Sample and SNP numbers before and after the QC. } For each batch (first column), the number of male (m)/female (f) samples and SNPs before and after QC are listed. Rate specifies the genotyping rate of samples within one batch after QC. }
    \begin{tabular}{lrrrrrr}
    \toprule
          & \multicolumn{2}{c}{pre-QC} &       & \multicolumn{3}{c}{post-QC} \\
\cmidrule{2-3}\cmidrule{5-7}          & samples (m/f) & SNPs  &       & samples (m/f) & SNPs  & Rate \\
\cmidrule{2-7}    Sanger12 & \num{1344}  (\num{614}/\num{730}) & \num{719665} &       & \num{998} (\num{463}/\num{535}) & \num{677036} & \num{0.998} \\
    Duke-NUS12 & \num{284} (\num{118}/\num{166}) & \num{716503} &       & \num{179} (\num{68}/\num{111}) & \num{682016} & \num{0.998} \\
    Duke-NUS3 & \num{96} (\num{48}/\num{48}) & \num{7713014} &       & \num{62} (\num{34}/\num{28}) & \num{657497} & \num{0.998} \\
    \bottomrule
    \end{tabular}%
    \label{tab:genoOverview}%
\end{table}%

\paragraph{Phasing and imputation.} Phasing and imputation were conducted in two separate steps. For phasing, I used SHAPEIT ( version 2.r727) \citep{Delaneau2012,Delaneau2013} to generate estimated haplotypes for each sample that passed the quality control. The window size for phasing was set to 2Mb, and the number of conditioning states per SNP to \num{200}. All other parameters were set to default values. The phased gentoypes were then imputed with IMPUTE2  (version 2.3.0) \citep{Marchini2007, Howie2009} based on the combined \num{1000} Genomes \citep{1000Genomes2015} and UK10K \citep{UK10KConsortium2015} reference panel. I set the imputation interval to 3Mb,  with a buffer region of \num{250}kb on either side of the analysis interval. As suggested in the user manual, I used an effective population size of \num{20000} and set the number of reference haplotypes to use to \num{1000}. Again, for the additional, non-specified parameters the default was used.

\paragraph{Combining datasets.} I combined the three genotype batches after imputation and filtered them again on a per-sample and per-marker level. On the per-sample level, I excluded related individuals because of the difficulties that might arise in adjusting for relatedness in the processing of the phenotypes via dimensionality reduction. A more detailed explanation will follow in \cref{section:DimRed-heart}. Relatedness was estimated by the proportion of SNPs shared between two individuals and subsequent calculation of identity by descent estimated as PI\_HAT on the genotyped SNPs via PLINK as described by \citep{Anderson2010}. For any pair of individuals with a PI\_HAT of greater than \num{0.125}, the individual with the higher SNP calling rate was retained in the analysis. For the quality control on the per-marker level, I used the statistical information about the imputation certainty, the `info' metric,  given as additional output by IMPUTE2. The metric typically takes values between zero and one, with values closer to one indicating high imputation certainty. I exluded any SNP with an info score of less than \num{0.4} in at least one of the batches. Approximately \num{60}\% of all imputed SNPs were excluded based on this criterion.  After combining the datasets, I used SNPTEST (v2.5) \citep{Marchini2010} to  compute the MAF and p-value for deviation from Hardy-Weinberg equilibrium per SNP. SNPs with a deviation from HWE (\(p <0.001\)) and a minor allele count of less than \num{20} alleles (corresponding to a minor allele frequency of \num{0.008}) were removed, leading to a decrease in SNPs of another approximately \num{41}\%, a total reduction from imputed SNPs to SNPs that passed every filtering criteria of \num{23}\%.  A summary showing the magnitude of the number of imputed SNPs per batch, the number of SNPs after imputation quality filtering and filtering for MAF and HWE deviation is depicted \cref{fig:imputeQC}. Exact numbers can be found in \cref{tab:imputationQC}.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 20mm, clip, width=\textwidth]{Chapter5/Figures/combinedSNPsperChr.pdf}
	\caption[\textbf{Overview of SNP numbers after imputation and imputation quality control. }]{\textbf{Overview of SNP numbers after imputation and imputation quality control. } The imputation of the SNPs based on the genotypes from SNP arrays was done on a per-batch level. The number of SNPs for each batch after imputation is shown as red bars and is very similar for each of the three batches (exact numbers in \cref{tab:imputationQC}). About \num{40}\% of SNPs are retained after filtering for the `info` metric (light grey bars). The bars in dark grey show the final number of SNPs per chromosome. }
 	\label{fig:imputeQC}
\end{figure}
%
After imputation and imputation quality control, the dataset contains \num{9233118} SNPs from \num{1207} samples. IMPUTE2 yields imputed genotypes encoded in triplets of posterior probabilities for the possible allele combinations \((AA, AB, BB)\). These probabilites were converted into expected genotypes \(G\) by the dosage model \citep{Howie2011}:

\begin{equation}
	G = 0 \times p(AA) + 1 \times p(AB) + 2 \times p(BB) = p(AB) + 2 \times p(BB)
\end{equation}


\subsection{Phenotypes}
\label{subsection:phentoypes}
The phenotyping was done by my collaborators, in particular Antonio de Marvao. CMR imaging and generation of 3D models of the left ventricle derived from these images were conducted at Hammersmith Hospital, London. In the following, I will briefly describe the methodology of their automatic phenotyping approach. The technical details of the image aquisiton, the analysis and their improved performance over standard methods are described in detail in \citep{deMarvao2014}. 

In the automated phenotyping approach developed by Antonio de Marvao and colleagues, cardiac structures are accurately extracted from raw 3D CMR images (\cref{fig:segmentation}, \subfig{1}) to generate 3D models of the individuals' hearts  (\cref{fig:segmentation}, \subfig{3}). The cardiac structures of interest in this study were left ventricular cavity, myocardium and right ventricular bloodpool at end-diastole and end-systole. The approach uses a local database of segmented and quality controlled CMR images, atlases, to which each newly acquired image is compared. The database was created by Antonio, who initially selected \num{20} subjects and manually classfied the approximately \num{140000} voxels per image into the three categories named above. In the database generation phase, subsequent successful segmentations of new images described by the method below were added, yielding a total of \num{1072} images in the final database. In addition to serving as a database for the segmentation algorithm, the database images were used to generate a template image of average heart size, position and orientation. 

For each new image, six landmarks are manually placed on the image, which enables the subsequent image registration between the target and the atlas images. After registration, a multi-atlas PatchMatch algorithm finds corresponding patches of adjacent voxels within the atlas and target images (\cref{fig:segmentation},\subfig{2}). Each patch in the target image is given the label of the closest matching atlas patches and combining the labels of all patches produces the final segmentation. Lastly, the segmented image is registered to the template image to make the spatial coordinates in the 3D models consistent between all samples.  

Using a surface rendering algorithm allows for the extraction of information from a segmentation volume such as the left venticular myocardium into a surface representation. Through such an algorithm, the wall thickness, curvature and  fractional wall thickening at \num{27623} positions in the left ventricle were extracted for each individual (\cref{fig:segmentation}\subfig{2}). %In addition, the left ventricular mass was computed based on the volume and density of the myocard. 
\\

\begin{figure}[h]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip,width=\textwidth]{Chapter5/Figures/Segmentation.pdf}
	\caption[\textbf{Cardiac phenotyping based on CMR images. }]{\textbf{Cardiac phenotyping based on CMR images. }1. Detailed 3D images of the heart were acquired in the left ventricular short axis (LVSA) plane from base to apex. 2. The images were segmented into left ventricular myocardium (green), left ventricular blood pool (red) and right ventricular blood pool (yellow) and registered to a common template image via a multi atlas-based technique. 3. Through a surface rendering algorithm of the registered segmentations, a 3D model of the heart was generated and wall thickness measurements derived at \num{27623} positions of the left ventricle. The left ventricle is shown in solid colors, with the colorscheme representing average wall thickness, increasing from light to darker colors. As a point of reference, the right ventricle is depicted as a mesh.}
 	\label{fig:segmentation}
\end{figure}
%
To assess the reproducibility of the phenotyping approach, one individual was scanned eight times and the images segmented as described above. These repeat scans allowed for the quantification of variation in the segmentations by the coefficient of variation (CV). The CV is a standardised measure of dispersion and is defined as the ratio of the standard deviation to the mean value. I computed the CV for each of the \num{27623} positions in the 3D heart model across the eight scans and projected the results onto the template image (\cref{fig:reproducibility}). Overall, the dispersion is very low i.e. the reproducibility high. Only at the base of the left ventricle in proximity to the right ventricle can a slight increase in dispersion be observed (\cref{fig:reproducibility}, red area). The low dispersion shows the accuracy of the segmentation and surface rendering methods. Based on this result and further quality control criteria such as the comparison between the segmentations and manually labeled images (details in \citep{deMarvao2014} the wall thickness measurements were considered reliable phenotypes for subsequent analyses. 
\\ 

\begin{figure}[h]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip,width=0.5\textwidth]{Chapter5/Figures/Dispersion.pdf}
	\caption[\textbf{Phenotype reproducibility. }]{\textbf{Phenotype reproducibility. }The dispersion in left ventricular wall thickness at \num{27623} positions was computed as the standard deviation over the mean across eight segmentations derived from independent scans of one individual. The right ventricle is shown as a point of reference (mesh structure). }
 	\label{fig:reproducibility}
\end{figure}
%