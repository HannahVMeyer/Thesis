\section{Data set and imputation}
The dataset consists of phenotype and genotype data of \num{1008} prototrophic haploid \emph{Saccharomyces cerevisiae} segregants derived from a cross between a laboratory strain and a wine strain strain. It contains \num{11623} unique genotypic markers obtained via short-read sequencing for all \num{1008} segregants (no missing genotypes). For phenotyping, segregants were grown on agar plates in \num{46} different conditions, including different temperatures, pH and nutrient addition (see labels in \cref{fig:traitcorrelations}). The phenotypes were definded as end-point colony size normalized relative to growth on control medium. For the remainder of this chapter, a trait is defined as the normalised growth size in one condition. Out of the \num{1008} segregants, \num{303} segregants were phenotyped for all \num{46} traits.

\subsection{Missing data mechanism} 
In order to gain an understanding of the dataset, I first looked at the frequencies and distribution of missing values. There are \num{135} different combinations of missing values across the samples and the missing phenotypes are not evenly distributed (\cref{fig:missingness}\subfig{A}). Some traits such as cobalt chloride are present for almost all samples while others such as sorbitol or raffinose are lacking in more than a third of the samples. I used Little's global test for MCAR to analyse wether these observed data patterns can be acocunted for through a MCAR mechanism. Little's method tests the null hypothesis that the data is MCAR \citep{Little1988,Beaujean2015}, which can in this case be rejected with a p-value of \num{2e-34} (based on a \(\chi^2\) dsitribution, \(\chi^2=\)\num{5902}, \(df=\)\num{4631}). 

\begin{figure}[p]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, scale=0.85]{Chapter3/Figures/frequency-patterns.pdf}
	\caption[\textbf{Frequencies and distributions of missing values in the yeast phenotype data.} Generated via R function \textit{VIM::aggr}]{\textbf{Frequencies and distributions of missing values in the yeast phenotype data.} A. The full dataset contains normalised colony sizes for growth in \num{46} different conditions of \num{1008} genotyped yeast segregants. \num{306} segregants are fully genotyped (bar chart, orange bar). B. Fully-phenotyped dataset of \num{306} segregants with simulated missing values based on the observed missingness pattern for the entire pool of \num{1008} segregants. In both panels, the aggregation plot (middle) depicts all existing combinations of missing (blue) and non-missing (orange) values in the traits. The bar chart on its right shows the frequencies of occurrence of the different combinations. The histogram on the top shows the frequency of missing values for each trait (R Package: \emph{VIM} \citep{Templ2012}). }
 	\label{fig:missingness}
\end{figure}

Determining if data is MAR or MNAR cannot be tested for formally and relies on approximate measures and assumptions based on the experimental procedures \citep{SchaferGraham2002,Garson2015,Templ2012}. Garson suggests to use significance tests of missingness \citeyear{Garson2015}. If it can be demonstrated that \num{1} or more variables in the dataset are significantly correlated with missing values, missingness may be predictable, which is the requirement for imputing MAR data. In order to test for predictable missingness, I created an indicator matrix for the phenotype matrix, where observed values where encoded as \num{0} and missing values as \num{1}. For each of the \num{46} traits in the dataset, I correlated the observed values across all samples with each column of the indicator matrix, i.e. the missingness patterns per trait. If all values were observed for a given trait, all values in the indicator matrix in this column were equal to \num{0} and the correlation between the trait and the missingness was set to NA. \Cref{fig:missingnesscorrelations} shows these correlation patterns between the phenotypes and the missing values per trait. The p-values of the correlations were adjusted for multiple testing via Benjamini and Hochberg's method \citep{Benjamini1995} and only significant correlations are depicted (\(\text{FDR} < 0.2\)).  For traits like cobalt chloride and magnesium sulfate where little data is missing, many entries are NA. Overall, for a number of traits and missingness patterns, there is sufficient evidence for predictable missingness and MAR assumptions for further analyses were considered valid. Most importantly, for data with MAR, the missing data mechanism is ignorable for maximum likelihood based methods and no further adjustments for the mechansims have to be made in the modeling \citep{Rubin1976,Little1988}. Thus, the MAR assumption of missingness in the yeast data allows for imputation via the likelihood-based method of multiple imputation and LMMs.


\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.9\textwidth]{Chapter3/Figures/correlation_missingness.pdf}
	\caption[\textbf{Correlations of observed phenotypes with missing data values.} Generated via R function \textit{corrplot::corrplot}]{\textbf{Correlations of observed phenotypes with missing data values}. For each of the \num{46} traits, the Spearman's rank correlation coefficient \(\rho\) was computed with each column of the indicator matrix of the phenotypes, containing 0 for observed values and 1 for missing values. The p-values of the correlations were adjusted for multiple testing according to Benjamini and Hochberg's method \citep{Benjamini1995}. The strength and the direction of significant correlations (\(\text{FDR} < 0.2\)) are depicted above, with the original phenotypes in rows and the indicator matrix of the phenotypes across columns. Unsignificant correlations are left blank. Grey squares indicate NA, i.e. columns in the indicator matrix for which no traits were missing when correlated with the observed values for a given trait. }
 	\label{fig:missingnesscorrelations}
\end{figure}

\subsection{Imputation via MICE} 
Impution of missing values requires an understanding of which missing trait values can be reliable imputed and to find the best parameter settings for the imputation. In order to do this, I needed a fully phenotyped dataset with the same structure as the yeast dataset, where missing values could be introduced, imputed and subsequently compared to the true values. I chose a simple approach and used the subset of the \num{303} fully phenotyped samples and introduced missing values with a similar pattern of missingness as observed in the original dataset. The results for the real (\cref{fig:missingness}\subfig{A}) and simulated (\cref{fig:missingness}\subfig{B}) dataset are similar in terms of frequencies and combination of missing/non-missing traits. I used this simulated dataset as input to the imputation framework based on multiple imputation by chain equations (MICE) \citep{vanBuuren2011}. 

MICE belongs to the general class of multiple imputation frameworks, where several imputed versions of the dataset are generated and each variable is imputed separately. The imputed values are chosen from plausible values drawn from a distribution that is specific for each variable, in this case for each trait. This distribution is derived from the dataset \(X \in R^{N,P}\) itself,  with \(X\) split into missing and observed parts \(X = (X_\text{miss}, X_\text{obs})\), the binary indicator matrix for missingness \(M \in R^{N,P}\) and a set of predictor variables \(Z\). The MICE algorithm is usually divided into \num{4} steps \citep{Rubin1978,vanBuuren1999,Pigott2001}:
\begin{enumerate}
\item Specify the posterior predictive density \(p(X_\text{miss} | Z, M)\) given the non-response mechanism  \(p(M | X)\)  and the complete data model  \(p(X)\).
\item Draw imputations from this density to produce \(m\) complete data sets. 
\item Perform \(m\) complete-data analyses on each completed data matrix. 
\item Pool the \(m\) analyses results into final point and variance estimates.
\end{enumerate}
Garson describes the possibilty of switching step \num{3} and \num{4} \citeyear{Garson2015}, where the multiple imputations are first pooled and the subsequent analyses run on the pooled estimates. Employing this approach allows me to  obtain reliable imputation estimates while having to estimate the variance components via LiMMBo only once. As described in the previous chapter, LiMMBo strongly reduces the computation time for the variance decomposition, but it is still the time-consuming factor in the analysis. 

The two main choices in applying MICE for imputation have to be made in step 1: the type of the imputation model and the choice of predictor variables. 

\paragraph{Imputation model.} From the different imputation models available (examples described in \citep{vanBuuren2011}), I found predictive mean matching (PMM), a semi-parametric method which preserves non-linear relations in the data \citep{Little1988,vanBuuren2011}, a fast and sensible imputation option.  In brief, PMM finds the mean and covariance of the multi-variate distribution \(X\) with missing values (often simply based on the complete cases). Subsequently, for each incomplete sample it predicts the missing values \(X_\text{miss}\) based on \(X_\text{obs}\) and the provided predictor variables \(Z\). In addition, values of the complete samples for the same set of \(X_\text{miss}\) are predicted. The predicted values of the incomplete sample are than matched to the predicted values of the complete samples and the closest match is chosen. The imputed values for the incomplete sample are set to the observed values of the closest match \citep{Little1988}. In this way, only realistic and theoretically observable values (assuming proper quality control of the data prior to imputation) are imputed.

\paragraph{Predictor variables.} Collins and colleagues show, that as many valid predictor variables as possible should be included in the imputation to obtain the least amount of bias and maximal certainty about the predictions \citeyear{Collins2001}. In addition, Schafer demonstrated that using this strategy makes MAR assumptions more plausible \citep{Schafer1997}. However, not all predictors will be relevant and the choice of predictors can be done on a per-variable level. In order to select suitable predictors for each trait, I first computed the pairwise Spearman correlation coefficient \(\rho\) for all traits across the \num{303} fully-phenotyped segregants. Some of the traits like cadmium chloride or neomycin show very little correlation to any of the other traits, while many of the traits based on growth on different carbohydrate resources form a large cluster of moderate to strong correlation (\cref{fig:traitcorrelations}). 
I tested several sets of predictor variables, either using all traits as predictors or chosing predictors based on the pairwise \(\rho\) of the traits. For each trait, I included predictors that showed a correlation higher than a predefined threshold (\(\rho =\left\{0.1, 0.2, 0.3\right\}\)). In addition, I restricted the predictors to traits that had been measured in at least 20\% of the samples in the dataset. This excluded cadmium chloride  (21\% missing), hydrogen peroxide (24\%), raffinose (34\%), sorbitol (41\%) and YPD:4C (20\%) as predictor variables, but did not exclude them from being imputed.

\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.9\textwidth]{Chapter3/Figures/correlation_pheno_noNA.pdf}
	\caption[\textbf{Pairwise correlations of \num{46} growth traits in \emph{Saccharomyces cerevisiae}.} Generated via R function \textit{corrplot::corrplot}]{\textbf{Pair-wise correlations of \num{46} growth traits in \emph{Saccharomyces cerevisiae}.} For each trait pair, Spearman's correlation coefficient \(\rho\) and the p-values of the correlation were computed. The p-values were adjusted for multiple testing according to Benjamini and Hochberg's method \citep{Benjamini1995}. The strength and the direction of significant correlations (\(p < 0.05\)) are depicted above. Unsignificant correlations are left blank. The traits are clustered based on complete-linkage clustering of \((1-\rho)\) as distance measurement.}
 	\label{fig:traitcorrelations}
\end{figure}


Further parameters for MICE are the number of imputed datasets \(m\) (set to \(m=20\)) and the number of iterations \(maxit\) (set to \(maxit=30\)). For each predictor set-up, I initiated MICE with the same seed for the random number generator to ensure comparability. After imputation, I evaluated the goodness of the imputation  by computing the Spearman correlation of the imputed values (averaged across iterations \(m\)) to the experimentally observed ones (\cref{fig:mice}). Traits where the imputed values correlated to the original ones by more then \num{95}\% in at least one of the predictor set-ups were retained in the analysis. For \num{5} traits (cadmium chloride, hydrogen peroxide, raffinose, YNB:ph8, YPD:4C), no suitable predictors could be determined and these were excluded from further analyses (\cref{fig:mice}, red labels). For each trait, I chose the predictor scheme that yielded the highest correlation between the imputed and observed data for the imputation of the missing values in the full dataset. Missing values were imputed in segregants that were phenotyped for at least \num{80}\% of the traits. The final dataset contained \num{981} segregants with phenotypes for \num{41} traits each. 
 	
\begin{figure}[hbtp]
	\centering
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=01\textwidth]{Chapter3/Figures/imputation_correlation_median_imputationvalue.pdf}
	\caption[\textbf{Correlation between imputed and experimentally observed trait values.}]{\textbf{Correlation between imputed and experimentally observed trait values.} In the subset of \num{306} fully phenotyped samples, missing values were introduced and subsequently imputed via MICE. Different predictor sets were tested based on Spearman's correlation coefficient: traits were considered predictors if their correlation with the target trait was greater than a given threshold. For each predictor setup (all traits as predictors and predictors passing the corrleation threshold \(\rho =\left\{0.1, 0.2, 0.3\right\}\)), \(m=20\) imputed datasets and \(maxit=30\) iterations of MICE were conducted. The goodness of the imputation was evaluated by computing the correlation of the imputed values (averaged across iterations \(m\)) to the experimentally observed ones. Traits with at least one correlation greater than the \num{0.95} threshold (black vertical line) were retained in the dataset. For traits labeled in red, the imputation was considered to be unreliable and the traits were excluded from further analyses. }
 	\label{fig:mice}
\end{figure}


